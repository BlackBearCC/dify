"""æ‰¹é‡æ•…äº‹ç”Ÿæˆå·¥ä½œæµ - ä»…CSVä¿å­˜ç‰ˆ
åŸºäºæ–¹çŸ¥è¡¡ä¸–ç•Œè§‚ï¼ŒæŒ‰ç…§æŒ‡å®šç±»åˆ«æ‰¹é‡ç”Ÿæˆæ•…äº‹æ–‡æœ¬ã€‚
"""

import asyncio
import os
import json
import logging
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from datetime import datetime
from typing import Dict, Any, List, Optional

from core.graph import StateGraph
from core.base import BaseNode
from core.types import Message, MessageRole

logger = logging.getLogger(__name__)


class StoryBatchWorkflow:
    """æ•…äº‹ç”Ÿæˆå·¥ä½œæµï¼ˆæ‰¹é‡ï¼ŒCSVæŒä¹…åŒ–ï¼‰"""

    def __init__(self, llm=None):
        self.llm = llm
        self.graph: Optional[StateGraph] = None

        # é»˜è®¤é…ç½®
        self.current_config: Dict[str, Any] = {
            "batch_size": 20,  # æ¯æ‰¹ç”Ÿæˆæ•…äº‹æ•°é‡
            "total_target": 200,  # æ€»æ•…äº‹æ•°é‡
            "story_categories": [
                "æ—¥å¸¸", "æ ¡å›­", "ç§‘å¹»", "æ‚¬ç–‘", "å¥‡å¹»", "çˆ±æƒ…"
            ],
            "csv_output": {
                "enabled": True,
                "output_dir": "workspace/story_output",
                "filename": "stories_batch_output.csv",
                "encoding": "utf-8-sig",
            },
        }

    # ---------------------------------------------------------------------
    # å›¾åˆ›å»º
    # ---------------------------------------------------------------------
    async def create_story_graph(self) -> StateGraph:
        """åˆ›å»ºæ•…äº‹ç”ŸæˆçŠ¶æ€å›¾"""
        self.graph = StateGraph(name="story_batch_generation")

        planning_node = StoryPlanningNode()
        generate_node = StoryGenerateNode()
        csv_save_node = StoryCSVSaveNode()

        self.graph.add_node("story_planning", planning_node)
        self.graph.add_node("story_generate", generate_node)
        self.graph.add_node("csv_save", csv_save_node)

        self.graph.add_edge("story_planning", "story_generate")
        self.graph.add_edge("story_generate", "csv_save")

        # å¾ªç¯æ¡ä»¶è¾¹ï¼šå¦‚æœæœªå®Œæˆï¼Œåˆ™ç»§ç»­ç”Ÿæˆä¸‹ä¸€æ‰¹
        def loop_condition(state: Dict[str, Any]):
            if state.get("generation_complete", False):
                return "__end__"
            return "story_generate"

        self.graph.add_conditional_edges("csv_save", loop_condition)

        self.graph.set_entry_point("story_planning")
        return self.graph

    # ---------------------------------------------------------------------
    # å·¥ä½œæµæ‰§è¡Œ
    # ---------------------------------------------------------------------
    async def execute(self, config: Optional[Dict[str, Any]] = None):
        """ç›´æ¥æ‰§è¡Œå·¥ä½œæµå¹¶è¿”å›æœ€ç»ˆçŠ¶æ€"""
        cfg = self.current_config.copy()
        if config:
            cfg.update(config)

        initial_state = {
            "config": cfg,
            "batch_size": cfg.get("batch_size"),
            "total_target": cfg.get("total_target"),
            "story_categories": cfg.get("story_categories"),
            "llm": self.llm,
            "current_batch_index": 0,
        }

        if not self.graph:
            await self.create_story_graph()
        compiled_graph = self.graph.compile()
        final_state = await compiled_graph.invoke(initial_state)
        return final_state

    async def execute_stream(self, config: Optional[Dict[str, Any]] = None):
        """æµå¼æ‰§è¡Œï¼Œyield æ¯ä¸ªæ‰§è¡Œäº‹ä»¶"""
        cfg = self.current_config.copy()
        if config:
            cfg.update(config)
        state = {
            "config": cfg,
            "batch_size": cfg.get("batch_size"),
            "total_target": cfg.get("total_target"),
            "story_categories": cfg.get("story_categories"),
            "llm": self.llm,
            "current_batch_index": 0,
        }
        if not self.graph:
            await self.create_story_graph()
        compiled_graph = self.graph.compile()
        async for event in compiled_graph.stream(state):
            yield event


# -------------------------------------------------------------------------
# Nodes
# -------------------------------------------------------------------------
class StoryPlanningNode(BaseNode):
    """è§„åˆ’æ•…äº‹ç±»åˆ«åŠæ‰¹æ¬¡"""

    def __init__(self):
        super().__init__(name="story_planning", stream=False)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        batch_size = input_data.get("batch_size", 20)
        total_target = input_data.get("total_target", 200)
        categories = input_data.get("story_categories", [])

        total_batches = (total_target + batch_size - 1) // batch_size

        plan = {
            "total_batches": total_batches,
            "batch_size": batch_size,
            "batch_categories": [],
        }

        # ç®€å•å¾ªç¯åˆ†é…ç±»åˆ«
        for idx in range(total_batches):
            plan["batch_categories"].append(
                categories[idx % len(categories)]
            )

        out = input_data.copy()
        out["plan"] = plan
        out["current_batch_index"] = 0
        return out


class StoryGenerateNode(BaseNode):
    """ç”Ÿæˆæ•…äº‹æ–‡æœ¬"""

    def __init__(self):
        super().__init__(name="story_generate", stream=False)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        llm = input_data.get("llm")
        plan = input_data.get("plan", {})
        current_index = input_data.get("current_batch_index", 0)
        batch_size = input_data.get("batch_size", 20)

        if current_index >= plan.get("total_batches", 0):
            # æ‰€æœ‰æ‰¹æ¬¡å®Œæˆ
            out = input_data.copy()
            out["generation_complete"] = True
            return out

        category = plan.get("batch_categories", [])[current_index]

        prompt = self._build_prompt(batch_size, category)

        stories: List[Dict[str, str]] = []

        if llm:
            try:
                messages = [Message(role=MessageRole.USER, content=prompt)]
                content = ""
                async for chunk in llm.stream_generate(messages, return_dict=True):
                    content += chunk.get("content", "")
                json_str = self._extract_json_from_content(content)
                from parsers.json_parser import JSONParser
                parser = JSONParser()
                parsed = parser.parse(json_str)
                stories = parsed.get("stories", []) if parsed else []
            except Exception as e:
                logger.error(f"LLMç”Ÿæˆå¤±è´¥: {e}")
        # å¦‚æœllmä¸å¯ç”¨æˆ–ç”Ÿæˆå¤±è´¥ï¼Œç”Ÿæˆå ä½æ•°æ®
        if not stories:
            stories = [
                {
                    "æ ‡é¢˜": f"ç¤ºä¾‹æ•…äº‹_{current_index}_{i}",
                    "å†…å®¹": f"è¿™æ˜¯ç±»åˆ«{category}çš„ç¤ºä¾‹æ•…äº‹æ­£æ–‡_{i}ã€‚"
                }
                for i in range(batch_size)
            ]

        out = input_data.copy()
        out["generated_stories"] = stories
        out["current_batch_index"] = current_index + 1
        return out

    @staticmethod
    def _build_prompt(batch_size: int, category: str) -> str:
        return f"""
è¯·åˆ›ä½œ {batch_size} ç¯‡ç±»åˆ«ä¸º"{category}"çš„åŸåˆ›çŸ­ç¯‡æ•…äº‹ï¼Œæ¯ç¯‡ 200-400 å­—ï¼Œå¹¶æä¾›ä¸€ä¸ªç®€æ´æ ‡é¢˜ã€‚

è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š
```json
{{
  "stories": [
    {{ "æ ‡é¢˜": "...", "å†…å®¹": "..." }},
    ... å…± {batch_size} é¡¹ ...
  ]
}}
```"""

    @staticmethod
    def _extract_json_from_content(content: str) -> str:
        import re
        pattern = r"```json\s*(.*?)\s*```"
        matches = re.findall(pattern, content, re.DOTALL | re.IGNORECASE)
        if matches:
            return matches[0].strip()
        # Fallback
        pattern2 = r"\{.*\}"
        matches2 = re.findall(pattern2, content, re.DOTALL)
        return matches2[0].strip() if matches2 else content.strip()


class StoryCSVSaveNode(BaseNode):
    """ä¿å­˜æ•…äº‹åˆ°CSVï¼ˆè¿½åŠ æ¨¡å¼ï¼‰"""

    def __init__(self):
        super().__init__(name="csv_save", stream=False)

    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        stories: List[Dict[str, str]] = input_data.get("generated_stories", [])
        cfg = input_data.get("config", {})
        batch_idx = input_data.get("current_batch_index", 1)

        if not stories:
            return input_data  # æ— æ•°æ®å¯ä¿å­˜

        csv_cfg = cfg.get("csv_output", {})
        out_dir = csv_cfg.get("output_dir", "workspace/story_output")
        filename = csv_cfg.get("filename", "stories_batch_output.csv")
        encoding = csv_cfg.get("encoding", "utf-8-sig")

        os.makedirs(out_dir, exist_ok=True)
        path = os.path.join(out_dir, filename)

        write_header = not os.path.exists(path)
        import csv
        with open(path, "a", newline="", encoding=encoding) as f:
            writer = csv.DictWriter(f, fieldnames=["æ‰¹æ¬¡", "æ ‡é¢˜", "å†…å®¹", "ç±»åˆ«", "ç”Ÿæˆæ—¶é—´"])
            if write_header:
                writer.writeheader()
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            for st in stories:
                writer.writerow({
                    "æ‰¹æ¬¡": f"ç¬¬{batch_idx}æ‰¹",
                    "æ ‡é¢˜": st.get("æ ‡é¢˜", ""),
                    "å†…å®¹": st.get("å†…å®¹", ""),
                    "ç±»åˆ«": cfg.get("story_categories", [])[ (batch_idx -1) % len(cfg.get("story_categories", [])) ],
                    "ç”Ÿæˆæ—¶é—´": timestamp,
                })

        logger.info(f"âœ… å·²ä¿å­˜ {len(stories)} ç¯‡æ•…äº‹åˆ° {path}")

        out = input_data.copy()
        out["csv_path"] = path
        return out


# -------------------------------------------------------------------------
# æµ‹è¯•è¿è¡Œ
# -------------------------------------------------------------------------
if __name__ == "__main__":
    async def _test():
        print("ğŸš€ å¼€å§‹æ‰¹é‡æ•…äº‹ç”Ÿæˆæµ‹è¯• ...")
        
        workflow = StoryBatchWorkflow(llm=None)  # æ— LLMï¼Œç”¨ç¤ºä¾‹æ•°æ®
        result = await workflow.execute({
            "total_target": 60,
            "batch_size": 15,
            "story_categories": ["æ—¥å¸¸", "å¥‡å¹»", "æ‚¬ç–‘"],
        })
        print("ğŸ‰ å®Œæˆ! æœ€ç»ˆçŠ¶æ€é”®:", list(result.keys()))
        print("CSVè·¯å¾„:", result.get("csv_path"))
    asyncio.run(_test()) 