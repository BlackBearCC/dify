version: 0.3.1
kind: app
app:
  name: Simple LLM Chat
  mode: workflow
  icon: ğŸ¤–
  icon_background: '#FFEAD5'
  description: ç®€å•çš„LLMå¯¹è¯å·¥ä½œæµ
  use_icon_as_answer_icon: false
dependencies: []
workflow:
  conversation_variables: []
  environment_variables: []
  features:
    opening_statement:
      enabled: true
      opening_statement: ä½ å¥½ï¼æˆ‘æ˜¯AIåŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ
    suggested_questions:
      enabled: true
      questions:
        - è¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±
        - ä½ èƒ½å¸®æˆ‘åšä»€ä¹ˆï¼Ÿ
        - ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ
    speech_to_text:
      enabled: false
    text_to_speech:
      enabled: false
      language: zh-Hans
      voice: alloy
    citation:
      enabled: false
    moderation:
      enabled: false
  graph:
    nodes:
      - id: start
        type: start
        data:
          title: å¼€å§‹
          desc: å·¥ä½œæµå¼€å§‹
          type: start
          variables:
            - variable: query
              label: ç”¨æˆ·é—®é¢˜
              description: ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
              type: text-input
              required: true
              hide: false
              max_length: 1000
              options: []
              allowed_file_types: []
              allowed_file_extensions: []
              allowed_file_upload_methods: []
        position:
          x: 80
          y: 200
      - id: llm-node
        type: llm
        data:
          title: LLMé—®ç­”
          desc: ä½¿ç”¨LLMå›ç­”ç”¨æˆ·é—®é¢˜
          type: llm
          model:
            provider: openai
            name: gpt-3.5-turbo
            mode: chat
            completion_params:
              temperature: 0.7
              max_tokens: 1000
              top_p: 1.0
              frequency_penalty: 0.0
              presence_penalty: 0.0
          prompt_template:
            - role: system
              text: ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œè¯·å‹å¥½ä¸”ä¸“ä¸šåœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
            - role: user
              text: "{{#start.query#}}"
          memory:
            enabled: false
          vision:
            enabled: false
          jinja2_variables: []
        position:
          x: 350
          y: 200
      - id: answer-node
        type: answer
        data:
          title: å›ç­”
          desc: è¾“å‡ºLLMçš„å›ç­”
          type: answer
          answer: "{{#llm-node.text#}}"
        position:
          x: 620
          y: 200
    edges:
      - id: start-llm-node
        source: start
        target: llm-node
      - id: llm-node-answer-node
        source: llm-node
        target: answer-node
    viewport:
      x: 0
      y: 0
      zoom: 1