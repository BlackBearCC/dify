"""ç¬‘è¯ç”Ÿæˆå·¥ä½œæµ - åŸºäºæ–¹çŸ¥è¡¡äººè®¾çš„ç¬‘è¯åˆ›ä½œç³»ç»Ÿ
æ ¹æ®ä¸»è§’çš„æ€§æ ¼ç‰¹ç‚¹ç”Ÿæˆç¬¦åˆäººè®¾çš„å¹½é»˜å†…å®¹ï¼Œæ”¯æŒæ‰¹é‡ç”Ÿæˆå‡ åƒæ¡ä¸é‡æ ·çš„ç¬‘è¯
"""

import json
import asyncio
import random
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path
import psycopg2
from psycopg2.extras import RealDictCursor

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from core.graph import StateGraph
from core.base import BaseNode
from llm.base import LLMFactory
from core.types import LLMConfig, TaskResult, Message, MessageRole

logger = logging.getLogger(__name__)

class JokeWorkflow:
    """ç¬‘è¯ç”Ÿæˆå·¥ä½œæµç®¡ç†å™¨"""
    
    def __init__(self, llm=None):
        self.llm = llm
        self.graph = None

        self.current_config = {
            'batch_size': 50,  # æ¯æ‰¹ç”Ÿæˆçš„ç¬‘è¯æ•°é‡
            'total_target': 1000,  # æ€»ç›®æ ‡æ•°é‡
            'joke_categories': [
                'å“²å­¦æ—¥å¸¸æ¢—', 'ç§‘å­¦åŒå…³æ¢—', 'é€»è¾‘ç”Ÿæ´»æ¢—', 
                'æ–‡å­—æ¸¸æˆæ¢—', 'ç”Ÿæ´»ç§‘å­¦æ¢—', 'åå·®å¹½é»˜æ¢—'
            ],
            'difficulty_levels': ['ç®€å•', 'ä¸­ç­‰', 'å¤æ‚'],
            'humor_styles': ['å†·å¹½é»˜', 'è‡ªå˜²', 'è§‚å¯Ÿå¼', 'åå·®èŒ'],
            'csv_output': {
                'enabled': True,
                'output_dir': 'workspace/joke_output',
                'filename': 'jokes_batch_output.csv',
                'encoding': 'utf-8-sig'  # æ”¯æŒä¸­æ–‡çš„CSVç¼–ç 
            },
            'database_enabled': True,  # å¯ç”¨æ•°æ®åº“åŠŸèƒ½
            'pg_config': {
                'host': 'localhost',
                'port': 5432,
                'database': 'postgres',  # ä½¿ç”¨é»˜è®¤çš„postgresæ•°æ®åº“
                'user': 'postgres',
                'password': '12345'  # ä½ çš„æ•°æ®åº“å¯†ç 
            }
        }
        
        # åˆå§‹åŒ–æ•°æ®åº“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.current_config.get('database_enabled', False):
            self._init_database()
        else:
            self.current_config['database_available'] = False
            logger.info("æ•°æ®åº“åŠŸèƒ½å·²ç¦ç”¨ï¼Œå°†ä»…ä½¿ç”¨CSVä¿å­˜")
    
    def _test_database_connection(self) -> bool:
        """æµ‹è¯•æ•°æ®åº“è¿æ¥æ˜¯å¦å¯ç”¨"""
        try:
            pg_config = self.current_config['pg_config']
            conn = psycopg2.connect(**pg_config)
            conn.close()
            return True
        except Exception as e:
            logger.warning(f"æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False

    def _init_database(self):
        """åˆå§‹åŒ–PostgreSQLæ•°æ®åº“å’Œè¡¨ç»“æ„"""
        # å…ˆæµ‹è¯•è¿æ¥
        if not self._test_database_connection():
            logger.warning("æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œå°†è·³è¿‡æ•°æ®åº“ç›¸å…³æ“ä½œ")
            self.current_config['database_available'] = False
            return
            
        try:
            pg_config = self.current_config['pg_config']
            
            # è¿æ¥æ•°æ®åº“
            conn = psycopg2.connect(**pg_config)
            cursor = conn.cursor()
            
            # åˆ›å»ºç¬‘è¯è¡¨
            create_table_sql = """
            CREATE TABLE IF NOT EXISTS jokes (
                id SERIAL PRIMARY KEY,
                joke_id VARCHAR(50) UNIQUE NOT NULL,
                category VARCHAR(50) NOT NULL,
                difficulty_level VARCHAR(20) NOT NULL,
                humor_style VARCHAR(30) NOT NULL,
                setup TEXT NOT NULL,
                punchline TEXT NOT NULL,
                context TEXT,
                character_traits TEXT[],
                tags TEXT[],
                rating INTEGER DEFAULT 0,
                is_used BOOLEAN DEFAULT FALSE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            
            CREATE INDEX IF NOT EXISTS idx_jokes_category ON jokes(category);
            CREATE INDEX IF NOT EXISTS idx_jokes_rating ON jokes(rating);
            CREATE INDEX IF NOT EXISTS idx_jokes_created_at ON jokes(created_at);
            """
            
            cursor.execute(create_table_sql)
            conn.commit()
            
            cursor.close()
            conn.close()
            
            logger.info("æ•°æ®åº“è¡¨ç»“æ„åˆå§‹åŒ–å®Œæˆ")
            self.current_config['database_available'] = True
            
        except Exception as e:
            logger.warning(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼Œå°†è·³è¿‡æ•°æ®åº“ç›¸å…³æ“ä½œ: {e}")
            # è®¾ç½®æ ‡å¿—ï¼Œè¡¨ç¤ºæ•°æ®åº“ä¸å¯ç”¨
            self.current_config['database_available'] = False
    
    def update_config(self, config_updates: Dict[str, Any]):
        """æ›´æ–°å·¥ä½œæµé…ç½®"""
        self.current_config.update(config_updates)
    
    async def create_joke_graph(self) -> StateGraph:
        """åˆ›å»ºç¬‘è¯ç”Ÿæˆå›¾å·¥ä½œæµ"""
        self.graph = StateGraph(name="joke_generation_workflow")
        
        # åˆ›å»ºèŠ‚ç‚¹
        theme_planning_node = ThemePlanningNode()  # ä¸»é¢˜è§„åˆ’èŠ‚ç‚¹
        joke_generate_node = JokeGenerateNode()   # ç¬‘è¯ç”ŸæˆèŠ‚ç‚¹
        database_save_node = JokeDatabaseSaveNode()  # æ•°æ®åº“ä¿å­˜èŠ‚ç‚¹
        
        # æ·»åŠ èŠ‚ç‚¹åˆ°å›¾
        self.graph.add_node("theme_planning", theme_planning_node)
        self.graph.add_node("joke_generate", joke_generate_node)
        self.graph.add_node("database_save", database_save_node)
        
        # å®šä¹‰èŠ‚ç‚¹è¿æ¥å…³ç³»
        self.graph.add_edge("theme_planning", "joke_generate")
        self.graph.add_edge("joke_generate", "database_save")
        
        # æ–°å¢æ¡ä»¶è¾¹ï¼šå¦‚æœå°šæœªå®Œæˆå…¨éƒ¨æ‰¹æ¬¡ï¼Œåˆ™å›åˆ°ç¬‘è¯ç”ŸæˆèŠ‚ç‚¹
        def loop_condition(state):
            """å½“å°šæœªå®Œæˆå…¨éƒ¨æ‰¹æ¬¡æ—¶ç»§ç»­å¾ªç¯åˆ° joke_generateï¼Œå¦åˆ™ç»“æŸ"""
            if state.get('generation_complete', False):
                return "__end__"
            return "joke_generate"
        
        self.graph.add_conditional_edges("database_save", loop_condition)
        
        # è®¾ç½®å…¥å£ç‚¹
        self.graph.set_entry_point("theme_planning")
        
        return self.graph
    
    async def execute_workflow_stream(self, config: Dict[str, Any], workflow_chat):
        """æµå¼æ‰§è¡Œç¬‘è¯ç”Ÿæˆå·¥ä½œæµ"""
        try:
            # å‡†å¤‡åˆå§‹è¾“å…¥
            initial_input = {
                'config': config,
                'batch_size': config.get('batch_size', 50),
                'total_target': config.get('total_target', 1000),
                'joke_categories': config.get('joke_categories', self.current_config['joke_categories']),
                'difficulty_levels': config.get('difficulty_levels', self.current_config['difficulty_levels']),
                'humor_styles': config.get('humor_styles', self.current_config['humor_styles']),
                'pg_config': config.get('pg_config', self.current_config['pg_config']),
                'workflow_chat': workflow_chat,
                'llm': self.llm
            }
            
            # åˆ›å»ºå¹¶ç¼–è¯‘å›¾å·¥ä½œæµ
            if not self.graph:
                await self.create_joke_graph()
            
            compiled_graph = self.graph.compile()
            
            # ä½¿ç”¨å›¾çš„æµå¼æ‰§è¡Œ
            async for stream_event in compiled_graph.stream(initial_input):
                event_type = stream_event.get('type')
                node_name = stream_event.get('node')
                
                if event_type == 'start':
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "ç¬‘è¯ç”Ÿæˆå·¥ä½œæµå¼€å§‹æ‰§è¡Œ...",
                        False
                    )
                
                elif event_type == 'node_start':
                    node_display_name = self._get_node_display_name(node_name)
                    workflow_chat.current_node = self._get_node_id(node_name)
                    
                    await workflow_chat.add_node_message(
                        node_display_name,
                        "å¼€å§‹æ‰§è¡Œ...",
                        "progress"
                    )
                    
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        f"{node_display_name}å¼€å§‹æ‰§è¡Œ...",
                        False
                    )
                
                elif event_type == 'node_streaming':
                    intermediate_result = stream_event.get('intermediate_result')
                    if intermediate_result and intermediate_result.state_update:
                        content_length = 0
                        for key in ['jokes_data', 'generated_jokes', 'checked_jokes']:
                            if key in intermediate_result.state_update:
                                if isinstance(intermediate_result.state_update[key], list):
                                    content_length = len(intermediate_result.state_update[key])
                                break
                        
                        if content_length > 0:
                            node_display_name = self._get_node_display_name(node_name)
                            await workflow_chat.add_node_message(
                                node_display_name,
                                f"æ­£åœ¨å¤„ç†ç¬‘è¯å†…å®¹... å½“å‰æ•°é‡: {content_length}",
                                "streaming"
                            )
                            
                            yield (
                                workflow_chat._create_workflow_progress(),
                                "",
                                f"æ­£åœ¨å¤„ç†ç¬‘è¯... å½“å‰æ•°é‡: {content_length}",
                                False
                            )
                
                elif event_type == 'node_complete':
                    node_display_name = self._get_node_display_name(node_name)
                    
                    if node_name == 'joke_generate':
                        result_content = "âœ… ç¬‘è¯ç”Ÿæˆå®Œæˆ"
                        if 'generated_jokes' in stream_event.get('output', {}):
                            jokes_data = stream_event['output']['generated_jokes']
                            if isinstance(jokes_data, list):
                                result_content = f"âœ… å·²æˆåŠŸç”Ÿæˆ{len(jokes_data)}æ¡ç¬‘è¯"
                    else:
                        result_content = "âœ… æ‰§è¡Œå®Œæˆ"
                        
                    await workflow_chat.add_node_message(
                        node_display_name,
                        result_content,
                        "completed"
                    )
                    
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        f"{node_display_name}æ‰§è¡Œå®Œæˆ",
                        False
                    )
                
                elif event_type == 'node_error':
                    error_msg = stream_event.get('error', 'æœªçŸ¥é”™è¯¯')
                    node_display_name = self._get_node_display_name(node_name)
                    
                    await workflow_chat.add_node_message(
                        node_display_name,
                        f"æ‰§è¡Œå¤±è´¥: {error_msg}",
                        "error"
                    )
                    
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "",
                        False
                    )
                
                elif event_type == 'final':
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "ç¬‘è¯ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œå®Œæˆ",
                        False
                    )
                
                else:
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "ç¬‘è¯ç”Ÿæˆå·¥ä½œæµæ‰§è¡Œä¸­...",
                        False
                    )
                
        except Exception as e:
            logger.error(f"ç¬‘è¯ç”Ÿæˆå·¥ä½œæµæµå¼æ‰§è¡Œå¤±è´¥: {e}")
            await workflow_chat.add_node_message(
                "ç³»ç»Ÿ",
                f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}",
                "error"
            )
            yield (
                workflow_chat._create_workflow_progress(),
                "",
                "",
                False
            )
    
    def _get_node_display_name(self, node_name: str) -> str:
        """è·å–èŠ‚ç‚¹æ˜¾ç¤ºåç§°"""
        name_mapping = {
            'theme_planning': 'ä¸»é¢˜è§„åˆ’',
            'joke_generate': 'ç¬‘è¯ç”Ÿæˆ',
            'quality_check': 'è´¨é‡æ£€æŸ¥',
            'database_save': 'æ•°æ®åº“ä¿å­˜'
        }
        return name_mapping.get(node_name, node_name)
    
    def _get_node_id(self, node_name: str) -> str:
        """è·å–èŠ‚ç‚¹ID"""
        id_mapping = {
            'theme_planning': 'planning',
            'joke_generate': 'generate',
            'quality_check': 'check',
            'database_save': 'save'
        }
        return id_mapping.get(node_name, node_name)

    def enable_database(self, pg_config: Optional[Dict] = None):
        """æ‰‹åŠ¨å¯ç”¨æ•°æ®åº“åŠŸèƒ½"""
        if pg_config:
            self.current_config['pg_config'].update(pg_config)
        
        self.current_config['database_enabled'] = True
        self._init_database()
        
        if self.current_config.get('database_available', False):
            logger.info("âœ… æ•°æ®åº“åŠŸèƒ½å·²æˆåŠŸå¯ç”¨")
            return True
        else:
            logger.warning("âš ï¸ æ•°æ®åº“å¯ç”¨å¤±è´¥ï¼Œå°†ç»§ç»­ä½¿ç”¨CSVä¿å­˜")
            return False


class ThemePlanningNode(BaseNode):
    """ä¸»é¢˜è§„åˆ’èŠ‚ç‚¹ - æ ¹æ®äººè®¾ç‰¹ç‚¹è§„åˆ’ç¬‘è¯ä¸»é¢˜å’Œé£æ ¼"""
    
    def __init__(self):
        super().__init__(name="theme_planning", stream=True)
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œä¸»é¢˜è§„åˆ’èŠ‚ç‚¹ - éæµå¼ç‰ˆæœ¬"""
        final_result = None
        async for result in self.execute_stream(input_data):
            final_result = result
        return final_result or input_data
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œä¸»é¢˜è§„åˆ’èŠ‚ç‚¹"""
        print("ğŸ¯ å¼€å§‹ä¸»é¢˜è§„åˆ’...")
        
        workflow_chat = input_data.get('workflow_chat')
        
        # è·å–é…ç½®å‚æ•°
        batch_size = input_data.get('batch_size', 50)
        total_target = input_data.get('total_target', 1000)
        joke_categories = input_data.get('joke_categories', [])
        
        if workflow_chat:
            await workflow_chat.add_node_message(
                "ä¸»é¢˜è§„åˆ’",
                f"æ­£åœ¨è§„åˆ’{total_target}æ¡ç¬‘è¯çš„ä¸»é¢˜åˆ†å¸ƒ...",
                "progress"
            )
        
        try:
            # è®¡ç®—éœ€è¦å¤šå°‘ä¸ªæ‰¹æ¬¡
            total_batches = (total_target + batch_size - 1) // batch_size
            
            # ä¸ºæ¯ä¸ªæ‰¹æ¬¡åˆ†é…ä¸»é¢˜
            theme_plan = {
                'total_batches': total_batches,
                'batch_size': batch_size,
                'category_distribution': {},
                'batch_themes': []
            }
            
            # å¹³è¡¡åˆ†é…å„ä¸ªç±»åˆ«
            categories_per_batch = max(1, len(joke_categories) // total_batches)
            
            for batch_idx in range(total_batches):
                # ä¸ºå½“å‰æ‰¹æ¬¡é€‰æ‹©ä¸»é¢˜ç±»åˆ«
                start_cat = (batch_idx * categories_per_batch) % len(joke_categories)
                end_cat = min(start_cat + categories_per_batch, len(joke_categories))
                batch_categories = joke_categories[start_cat:end_cat]
                
                # å¦‚æœç±»åˆ«ä¸å¤Ÿï¼Œä»å¤´å¼€å§‹è¡¥å……
                if len(batch_categories) < categories_per_batch:
                    remaining = categories_per_batch - len(batch_categories)
                    batch_categories.extend(joke_categories[:remaining])
                
                batch_theme = {
                    'batch_number': batch_idx + 1,
                    'categories': batch_categories,
                    'focus_trait': self._get_focus_trait(batch_idx),
                    'humor_emphasis': self._get_humor_emphasis(batch_idx)
                }
                
                theme_plan['batch_themes'].append(batch_theme)
            
            # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
            for theme in theme_plan['batch_themes']:
                for cat in theme['categories']:
                    theme_plan['category_distribution'][cat] = theme_plan['category_distribution'].get(cat, 0) + 1
            
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "ä¸»é¢˜è§„åˆ’",
                    f"âœ… è§„åˆ’å®Œæˆï¼š{total_batches}ä¸ªæ‰¹æ¬¡ï¼Œå¹³è¡¡åˆ†é…{len(joke_categories)}ä¸ªä¸»é¢˜ç±»åˆ«",
                    "success"
                )
            
            # è¾“å‡ºç»“æœ
            output_data = input_data.copy()
            output_data['theme_plan'] = theme_plan
            output_data['current_batch_index'] = 0
            
            logger.info(f"âœ… ä¸»é¢˜è§„åˆ’å®Œæˆï¼Œç”Ÿæˆäº†{total_batches}ä¸ªæ‰¹æ¬¡çš„ä¸»é¢˜åˆ†é…")
            yield output_data
            
        except Exception as e:
            logger.error(f"ä¸»é¢˜è§„åˆ’å¤±è´¥: {e}")
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "ä¸»é¢˜è§„åˆ’",
                    f"âŒ è§„åˆ’å¤±è´¥: {str(e)}",
                    "error"
                )
            raise Exception(f"ä¸»é¢˜è§„åˆ’å¤±è´¥: {str(e)}")
    
    def _get_focus_trait(self, batch_idx: int) -> str:
        """æ ¹æ®æ‰¹æ¬¡è·å–é‡ç‚¹äººè®¾ç‰¹å¾"""
        traits = [
            'ç†æ€§ä¸¥è°¨', 'å†…æ•›æ¸©å’Œ', 'æ¯’å¥¶ä½“è´¨', 'ç½‘ç»œè½ä¼',
            'å¤æ¿è®¤çœŸ', 'å­¦æœ¯ä¸“æ³¨', 'ç”Ÿæ´»ç»†è‡´', 'æ¸©å’Œåæ§½'
        ]
        return traits[batch_idx % len(traits)]
    
    def _get_humor_emphasis(self, batch_idx: int) -> str:
        """æ ¹æ®æ‰¹æ¬¡è·å–å¹½é»˜é‡ç‚¹"""
        emphasis = [
            'å†·å¹½é»˜', 'è‡ªå˜²å¼', 'è§‚å¯Ÿå¼', 'åå·®èŒ',
            'å­¦è€…é£èŒƒ', 'ç”Ÿæ´»æ™ºæ…§', 'æ„å¤–æƒŠå–œ', 'æ¸©å’Œåæ§½'
        ]
        return emphasis[batch_idx % len(emphasis)]


class JokeGenerateNode(BaseNode):
    """ç¬‘è¯ç”ŸæˆèŠ‚ç‚¹ - åŸºäºäººè®¾ç”Ÿæˆç¬¦åˆç‰¹ç‚¹çš„ç¬‘è¯"""
    
    def __init__(self):
        super().__init__(name="joke_generate", stream=True)
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œç¬‘è¯ç”ŸæˆèŠ‚ç‚¹ - éæµå¼ç‰ˆæœ¬"""
        final_result = None
        async for result in self.execute_stream(input_data):
            final_result = result
        return final_result or input_data
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œç¬‘è¯ç”ŸæˆèŠ‚ç‚¹ - åˆ†æ‰¹ç”Ÿæˆ"""
        print("ğŸ˜„ å¼€å§‹ç¬‘è¯ç”Ÿæˆ...")
        
        workflow_chat = input_data.get('workflow_chat')
        llm = input_data.get('llm')
        
        # è·å–ä¸»é¢˜è§„åˆ’æ•°æ®
        theme_plan = input_data.get('theme_plan', {})
        current_batch_index = input_data.get('current_batch_index', 0)
        batch_themes = theme_plan.get('batch_themes', [])
        
        if not batch_themes or current_batch_index >= len(batch_themes):
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "ç¬‘è¯ç”Ÿæˆ",
                    "âœ… æ‰€æœ‰æ‰¹æ¬¡çš„ç¬‘è¯ç”Ÿæˆå·²å®Œæˆï¼",
                    "success"
                )
            
            output_data = input_data.copy()
            output_data['generation_complete'] = True
            yield output_data
            return
        
        # è·å–å½“å‰æ‰¹æ¬¡ä¿¡æ¯
        current_batch = batch_themes[current_batch_index]
        batch_categories = current_batch['categories']
        focus_trait = current_batch['focus_trait']
        humor_emphasis = current_batch['humor_emphasis']
        batch_size = input_data.get('batch_size', 10)
        
        if workflow_chat:
            await workflow_chat.add_node_message(
                "ç¬‘è¯ç”Ÿæˆ",
                f"æ­£åœ¨ç”Ÿæˆç¬¬ {current_batch_index + 1}/{len(batch_themes)} æ‰¹æ¬¡ç¬‘è¯ï¼ˆ{batch_size}æ¡ï¼‰...",
                "progress"
            )
        
        # æ„å»ºç¬‘è¯ç”Ÿæˆæç¤ºè¯
        
        generation_prompt = f"""
è¯·åˆ›ä½œ{batch_size}æ¡çœŸæ­£å¥½ç¬‘çš„ç¬‘è¯ï¼Œé‡ç‚¹æ˜¯è¦è®©äººç¬‘å‡ºæ¥ï¼

## ç¬‘è¯ç»“æ„è¦æ±‚
æ¯æ¡ç¬‘è¯åŒ…å«ï¼š
- **å…³é”®è¯**ï¼šæœç´¢ç”¨å…³é”®è¯ç»„ï¼Œç”¨é€—å·åˆ†éš”ï¼ŒåŒ…å«ï¼šä¸»é¢˜ï¼Œé€‚ç”¨åœºåˆï¼Œæƒ…å¢ƒç­‰ï¼Œæ–¹ä¾¿æ£€ç´¢ï¼Œä¸è¦é‡å¤ç¬‘è¯å†…å®¹
- **ç¬‘è¯å†…å®¹**ï¼šå®Œæ•´çš„ç¬‘è¯ï¼ŒåŒ…å«æƒ…å¢ƒå’Œç¬‘ç‚¹ï¼Œ100-250å­—

## ç¬‘è¯åˆ›ä½œæ–¹å‘
è°éŸ³æ¢—ï¼Œè°éŸ³åŒå…³ï¼Œç¬¦åˆä»¥ä¸‹è¦æ±‚ï¼š
- è½»æ¾æœ‰è¶£ï¼Œè®©äººæƒ³ç¬‘
- ç¬¦åˆçˆ±ä¸Šç½‘å¹´è½»äººçš„å£å‘³ï¼Œæœ‰ç½‘æ„Ÿ
- è®©äººå¬å®Œç¬‘è¯æœ‰ä¸€ç§ ä½ ç‰›é€¼çš„æ„Ÿè§‰

# ç¤ºä¾‹
må’Œnæ‰“æ¶äº† mæœ€åè®¤é”™äº†ï¼Œå› ä¸ºI'm sorryã€‚
å°åŠ¨ç‰©ä»¬èšé¤ï¼Œåªæœ‰å°è±¡å¾ˆç”Ÿæ°”ï¼ŒåŸæ¥è¿™æ˜¯ä¸€ä¸ªæ°”è±¡å±€ã€‚
ä¸ºä»€ä¹ˆæŸ¯å—æ°¸è¿œéƒ½ç©¿é‚£å¥—è¡£æœ?å› ä¸ºä»–æ€•è¢«åˆ«äººè¯´:å“å”·:æ˜¯æ–°è¡£å“¦ã€‚
æœ‰ä¸€å—ç»ç’ƒå®ƒæœ‰ç‚¹å›°äº†ç„¶åå®ƒä»æ¥¼ä¸Šè·³ä¸‹æ¥å¹¶ä¸”è¯´:æ™šå®‰æˆ‘ç¢å•¦!
å°æœ‹å‹çš„å·§å…‹åŠ›èåŒ–æ‰åœ¨äº†åœ°ä¸Šï¼Œå°æœ‹å‹è¯´å¥½åƒæ³¥å‘€å¥½åƒæ³¥å‘€ï¼Œä½ å¬è§äº†å—ï¼Œå¥½æƒ³ä½ ã€‚
èƒèŸ¹å‡ºé—¨æ•£æ­¥ä¸å°å¿ƒæ’åˆ°äº†æ³¥é³…ï¼Œæ³¥é³…å¾ˆç”Ÿæ°”:"ä½ æ˜¯ä¸æ˜¯çå•Š?"èƒèŸ¹å¾ˆå§”å±ˆ:"ä¸æ˜¯å•Šï¼Œæˆ‘æ˜¯èƒèŸ¹!"
ä¸¤ä¸ªå¤§çˆ·åœ¨ä¸‹æ£‹ï¼Œå°å­©:å¤§çˆ·ä½ è½¦æ²¡äº†ã€‚å¤§çˆ·:ä»€ä¹ˆè½¦ï¼Œè¿™å« juã€‚å°å­©:å“¦ï¼Œå¤§çˆ·ä½ è‡ªè¡Œ ju è¢«äººéª‘èµ°äº†ã€‚
åˆšåˆšå‡ºé—¨ä¹°ç”Ÿèš,èµ°å‡ºè¶…å¸‚ä»–ä»¬çªç„¶è·³å‡ºè¢‹å­é’»è¿›åœŸé‡Œï¼Œå›æ¥ä¸€æƒ³ï¼ŒåŸæ¥æ˜¯èšå–œæ¬¢æ³¥ã€‚
è¯¸è‘›äº®ç«çƒ§èµ¤å£ï¼Œå€Ÿä¸œé£ï¼Œå€Ÿäº†å…«æ¬¡,å°±å˜æˆäº†è¯¸å…«å€Ÿ!
ä½ çŸ¥é“å—?å“†å•¦Aæ¢¦æ²¡æœ‰è„–å­æ˜¯å‡ºäºå«ç”Ÿè€ƒè™‘ã€‚ä¸ºä»€ä¹ˆ?å› ä¸ºâ€œè“è„–ç§¯æ³¥â€
å°é¸­å­å¯¹å°é¸¡è¯´:â€œå°é¸¡ï¼Œæˆ‘å–œæ¬¢ä½ â€å°é¸¡:ä½  duckä¸å¿…ã€‚

# è¾“å‡ºæ ¼å¼
è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡º{batch_size}æ¡ç¬‘è¯ï¼Œç¦æ­¢è¾“å‡ºä»»ä½•å…¶ä»–å†…å®¹ï¼š

```json
{{
  "jokes": [
    {{
      "å…³é”®è¯": "ç®€çŸ­ä¸»é¢˜å…³é”®è¯",
      "ç¬‘è¯å†…å®¹": "å®Œæ•´ç¬‘è¯å†…å®¹"
    }},
    {{
      "å…³é”®è¯": "ç®€çŸ­ä¸»é¢˜å…³é”®è¯", 
      "ç¬‘è¯å†…å®¹": "å®Œæ•´ç¬‘è¯å†…å®¹"
    }},
    // ... ç»§ç»­åˆ°ç¬¬{batch_size}æ¡
  ]
}}
```
"""
        
        # è°ƒç”¨LLMç”Ÿæˆç¬‘è¯
        if llm:
            try:
                from core.types import Message, MessageRole
                message = Message(role=MessageRole.USER, content=generation_prompt)
                messages = [message]
                
                logger.info(f"ç¬‘è¯ç”Ÿæˆæ‰¹æ¬¡ {current_batch_index + 1}: å¼€å§‹LLMè°ƒç”¨")
                
                # æµå¼è°ƒç”¨LLM
                final_content = ""
                async for chunk_data in llm.stream_generate(
                    messages, 
                    mode="think",
                    return_dict=True
                ):
                    content_part = chunk_data.get("content", "")
                    final_content += content_part
                
                logger.info(f"æ‰¹æ¬¡ {current_batch_index + 1} LLMç”Ÿæˆå®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(final_content)}")
                        
            except Exception as e:
                error_msg = f"æ‰¹æ¬¡ {current_batch_index + 1} LLMè°ƒç”¨å¤±è´¥: {str(e)}"
                logger.error(error_msg, exc_info=True)
                raise Exception(error_msg)
        else:
            raise Exception("LLMæœªåˆå§‹åŒ–")
        
        # è§£æJSONç»“æœ
        jokes_data = None
        try:
            json_content = self._extract_json_from_content(final_content)
            from parsers.json_parser import JSONParser
            parser = JSONParser()
            parsed_result = parser.parse(json_content)
            
            if parsed_result and 'jokes' in parsed_result:
                jokes_data = parsed_result
                generated_jokes = jokes_data.get('jokes', [])
                logger.info(f"æ‰¹æ¬¡ {current_batch_index + 1} æˆåŠŸè§£æï¼ŒåŒ…å« {len(generated_jokes)} æ¡ç¬‘è¯")
                
                if workflow_chat:
                    await workflow_chat.add_node_message(
                        "ç¬‘è¯ç”Ÿæˆ",
                        f"âœ… æ‰¹æ¬¡ {current_batch_index + 1} ç”Ÿæˆå®Œæˆï¼ˆ{len(generated_jokes)}æ¡ç¬‘è¯ï¼‰",
                        "success"
                    )
            else:
                raise Exception(f"æ‰¹æ¬¡è§£æå¤±è´¥ï¼šç¼ºå°‘jokeså­—æ®µ")
                
        except Exception as parse_error:
            logger.error(f"æ‰¹æ¬¡ {current_batch_index + 1} JSONè§£æå¤±è´¥: {parse_error}")
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "ç¬‘è¯ç”Ÿæˆ",
                    f"âš ï¸ æ‰¹æ¬¡ {current_batch_index + 1} è§£æå¤±è´¥ï¼Œè·³è¿‡",
                    "warning"
                )
            jokes_data = None
        
        # æ„å»ºè¾“å‡ºæ•°æ®
        output_data = input_data.copy()
        output_data['generated_jokes'] = jokes_data.get('jokes', []) if jokes_data else []
        output_data['current_batch_index'] = current_batch_index + 1
        
        print(f"âœ… æ‰¹æ¬¡ {current_batch_index + 1} ç¬‘è¯ç”Ÿæˆå®Œæˆ")
        yield output_data
    
    def _extract_json_from_content(self, content: str) -> str:
        """ä»ç”Ÿæˆå†…å®¹ä¸­æå–JSONéƒ¨åˆ†"""
        import re
        
        # æŸ¥æ‰¾```json...```ä»£ç å—
        json_pattern = r'```json\s*(.*?)\s*```'
        matches = re.findall(json_pattern, content, re.DOTALL | re.IGNORECASE)
        
        if matches:
            return matches[0].strip()
        
        # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•æŸ¥æ‰¾ä»¥{å¼€å¤´}ç»“å°¾çš„å†…å®¹
        json_pattern2 = r'\{.*\}'
        matches2 = re.findall(json_pattern2, content, re.DOTALL)
        
        if matches2:
            return matches2[0].strip()
        
        return content.strip()





class JokeDatabaseSaveNode(BaseNode):
    """æ•°æ®åº“ä¿å­˜èŠ‚ç‚¹ - å°†æ£€æŸ¥è¿‡çš„ç¬‘è¯ä¿å­˜åˆ°PostgreSQL"""
    
    def __init__(self):
        super().__init__(name="joke_database_save", stream=True)
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ•°æ®åº“ä¿å­˜èŠ‚ç‚¹ - éæµå¼ç‰ˆæœ¬"""
        final_result = None
        async for result in self.execute_stream(input_data):
            final_result = result
        return final_result or input_data
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œæ•°æ®åº“ä¿å­˜èŠ‚ç‚¹"""
        print("ğŸ’¾ å¼€å§‹ä¿å­˜ç¬‘è¯æ•°æ®...")
        
        workflow_chat = input_data.get('workflow_chat')
        generated_jokes = input_data.get('generated_jokes', [])
        pg_config = input_data.get('pg_config', {})
        config = input_data.get('config', {})
        current_batch_index = input_data.get('current_batch_index', 1)
        
        if not generated_jokes:
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "æ•°æ®åº“ä¿å­˜",
                    "âš ï¸ æ²¡æœ‰ç¬‘è¯éœ€è¦ä¿å­˜",
                    "warning"
                )
            yield input_data
            return
        
        if workflow_chat:
            await workflow_chat.add_node_message(
                "æ•°æ®åº“ä¿å­˜",
                f"æ­£åœ¨ä¿å­˜ç¬¬{current_batch_index}æ‰¹æ¬¡çš„{len(generated_jokes)}æ¡ç¬‘è¯...",
                "progress"
            )
        
        # å…ˆä¿å­˜åˆ°CSVæ–‡ä»¶ï¼ˆå¢é‡æ›´æ–°ï¼‰
        csv_save_result = await self._save_to_csv(generated_jokes, current_batch_index, workflow_chat, config)
        
        # å¦‚æœæ•°æ®åº“å¯ç”¨ï¼Œå†ä¿å­˜åˆ°æ•°æ®åº“
        db_save_result = None
        if config.get('database_enabled', False) and config.get('database_available', True) != False:
            db_save_result = await self._save_to_database(generated_jokes, pg_config, workflow_chat)
        else:
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "æ•°æ®åº“ä¿å­˜",
                    "âš ï¸ æ•°æ®åº“åŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡æ•°æ®åº“ä¿å­˜",
                    "warning"
                )
        
        # æ„å»ºæœ€ç»ˆè¾“å‡º
        output_data = input_data.copy()
        output_data.update({
            'csv_save_result': csv_save_result,
            'db_save_result': db_save_result,
            'save_success': csv_save_result.get('success', False) or (db_save_result and db_save_result.get('success', False)),
            'save_message': self._build_save_message(csv_save_result, db_save_result)
        })
        
        yield output_data
    
    async def _save_to_csv(self, generated_jokes: List[Dict], current_batch_index: int, workflow_chat=None, config=None) -> Dict:
        """ä¿å­˜ç¬‘è¯åˆ°CSVæ–‡ä»¶ï¼Œæ”¯æŒå¢é‡æ›´æ–°"""
        try:
            import csv
            from datetime import datetime
            
            # è·å–CSVé…ç½®
            csv_config = config.get('csv_output', {}) if config else {}
            output_dir = csv_config.get('output_dir', 'workspace/joke_output')
            filename = csv_config.get('filename', 'jokes_batch_output.csv')
            encoding = csv_config.get('encoding', 'utf-8-sig')
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(output_dir, exist_ok=True)
            
            # CSVæ–‡ä»¶è·¯å¾„
            csv_file = os.path.join(output_dir, filename)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå†³å®šæ˜¯å¦å†™å…¥è¡¨å¤´
            file_exists = os.path.exists(csv_file)
            
            # å†™å…¥CSVæ–‡ä»¶ï¼ˆè¿½åŠ æ¨¡å¼ï¼‰
            with open(csv_file, 'a', newline='', encoding=encoding) as f:
                fieldnames = ['æ‰¹æ¬¡', 'å…³é”®è¯', 'ç¬‘è¯å†…å®¹', 'ç”Ÿæˆæ—¶é—´']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                
                # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå…ˆå†™å…¥è¡¨å¤´
                if not file_exists:
                    writer.writeheader()
                
                # å†™å…¥å½“å‰æ‰¹æ¬¡çš„ç¬‘è¯
                timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                for joke in generated_jokes:
                    writer.writerow({
                        'æ‰¹æ¬¡': f"ç¬¬{current_batch_index}æ‰¹",
                        'å…³é”®è¯': joke.get('å…³é”®è¯', ''),
                        'ç¬‘è¯å†…å®¹': joke.get('ç¬‘è¯å†…å®¹', ''),
                        'ç”Ÿæˆæ—¶é—´': timestamp
                    })
            
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "CSVä¿å­˜",
                    f"âœ… ç¬¬{current_batch_index}æ‰¹æ¬¡{len(generated_jokes)}æ¡ç¬‘è¯å·²ä¿å­˜åˆ°CSVæ–‡ä»¶",
                    "success"
                )
            
            logger.info(f"âœ… CSVä¿å­˜å®Œæˆï¼šç¬¬{current_batch_index}æ‰¹æ¬¡{len(generated_jokes)}æ¡ç¬‘è¯ä¿å­˜åˆ° {csv_file}")
            
            return {
                'success': True,
                'count': len(generated_jokes),
                'file_path': csv_file,
                'batch_index': current_batch_index
            }
            
        except Exception as e:
            logger.error(f"CSVä¿å­˜å¤±è´¥: {e}")
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "CSVä¿å­˜",
                    f"âŒ CSVä¿å­˜å¤±è´¥: {str(e)}",
                    "error"
                )
            
            return {
                'success': False,
                'error': str(e)
            }
    
    async def _save_to_database(self, generated_jokes: List[Dict], pg_config: Dict, workflow_chat=None) -> Dict:
        """ä¿å­˜ç¬‘è¯åˆ°PostgreSQLæ•°æ®åº“"""
        try:
            # è¿æ¥æ•°æ®åº“
            conn = psycopg2.connect(**pg_config)
            cursor = conn.cursor()
            
            # æ‰¹é‡æ’å…¥ç¬‘è¯
            success_count = 0
            duplicate_count = 0
            error_count = 0
            
            for joke in generated_jokes:
                try:
                    # ç”Ÿæˆå”¯ä¸€ID
                    import uuid
                    joke_id = str(uuid.uuid4())[:8]
                    
                    insert_sql = """
                    INSERT INTO jokes (
                        joke_id, category, difficulty_level, humor_style,
                        setup, punchline, context, character_traits, tags, rating
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (joke_id) DO NOTHING
                    """
                    
                    cursor.execute(insert_sql, (
                        joke_id,
                        'è‡ªç”±åˆ›ä½œ',
                        'ä¸­ç­‰',
                        'å†·å¹½é»˜',
                        joke.get('å…³é”®è¯', ''),
                        joke.get('ç¬‘è¯å†…å®¹', ''),
                        '',
                        [],
                        joke.get('å…³é”®è¯', '').split(','),
                        80
                    ))
                    
                    if cursor.rowcount > 0:
                        success_count += 1
                    else:
                        duplicate_count += 1
                        
                except Exception as e:
                    logger.warning(f"ä¿å­˜å•æ¡ç¬‘è¯å¤±è´¥: {e}")
                    error_count += 1
                    continue
            
            # æäº¤äº‹åŠ¡
            conn.commit()
            cursor.close()
            conn.close()
            
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "æ•°æ®åº“ä¿å­˜",
                    f"âœ… æ•°æ®åº“ä¿å­˜å®Œæˆï¼š{success_count}æ¡æˆåŠŸï¼Œ{duplicate_count}æ¡é‡å¤ï¼Œ{error_count}æ¡å¤±è´¥",
                    "success"
                )
            
            logger.info(f"âœ… æ•°æ®åº“ä¿å­˜å®Œæˆï¼š{success_count}æ¡æˆåŠŸä¿å­˜")
            
            return {
                'success': True,
                'success_count': success_count,
                'duplicate_count': duplicate_count,
                'error_count': error_count
            }
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "æ•°æ®åº“ä¿å­˜",
                    f"âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {str(e)}",
                    "error"
                )
            
            return {
                'success': False,
                'error': str(e)
            }
    
    def _build_save_message(self, csv_result: Dict, db_result: Dict) -> str:
        """æ„å»ºä¿å­˜ç»“æœæ¶ˆæ¯"""
        messages = []
        
        if csv_result and csv_result.get('success'):
            messages.append(f"CSVä¿å­˜æˆåŠŸ({csv_result.get('count', 0)}æ¡)")
        elif csv_result:
            messages.append(f"CSVä¿å­˜å¤±è´¥({csv_result.get('error', 'æœªçŸ¥é”™è¯¯')})")
        
        if db_result and db_result.get('success'):
            messages.append(f"æ•°æ®åº“ä¿å­˜æˆåŠŸ({db_result.get('success_count', 0)}æ¡)")
        elif db_result:
            messages.append(f"æ•°æ®åº“ä¿å­˜å¤±è´¥({db_result.get('error', 'æœªçŸ¥é”™è¯¯')})")
        
        return "; ".join(messages) if messages else "ä¿å­˜å®Œæˆ"


# æœ¬åœ°æµ‹è¯•è¿è¡Œå…¥å£
async def main():
    """æœ¬åœ°æµ‹è¯•è¿è¡Œç¬‘è¯ç”Ÿæˆå·¥ä½œæµ"""
    print("ğŸ­ å¯åŠ¨æ–¹çŸ¥è¡¡ç¬‘è¯ç”Ÿæˆå·¥ä½œæµæœ¬åœ°æµ‹è¯•...")
    
    # ç®€å•çš„æ¨¡æ‹ŸèŠå¤©ç•Œé¢
    class MockWorkflowChat:
        def __init__(self):
            self.current_node = ""
        
        async def add_node_message(self, node_name: str, message: str, status: str):
            print(f"[{node_name}] {status}: {message}")
        
        def _create_workflow_progress(self):
            return "<div>å·¥ä½œæµè¿›åº¦</div>"
    
    try:
        # é…ç½®LLMï¼ˆå¦‚æœæœ‰æœ‰æ•ˆçš„APIå¯†é’¥ï¼‰
        llm = None
        try:
            from llm.doubao import DoubaoLLM
            from core.types import LLMConfig
            
            # è¿™é‡Œä½¿ç”¨æµ‹è¯•é…ç½®ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦æ›¿æ¢ä¸ºçœŸå®çš„APIå¯†é’¥
            llm_config = LLMConfig(
                provider="doubao",
                model_name="ep-20241230141654-5tvbr",
                api_key="b633a622-b5d0-4f16-a8a9-616239cf15d1",  # æ›¿æ¢ä¸ºçœŸå®çš„APIå¯†é’¥
                api_base="https://ark.cn-beijing.volces.com/api/v3"
            )
            llm = DoubaoLLM(config=llm_config)
            print("âœ… LLMé…ç½®æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ LLMé…ç½®å¤±è´¥ï¼Œå°†è·³è¿‡å®é™…ç”Ÿæˆ: {e}")
        
        # åˆå§‹åŒ–å·¥ä½œæµ
        workflow = JokeWorkflow(llm=llm)
        print("âœ… ç¬‘è¯å·¥ä½œæµåˆå§‹åŒ–å®Œæˆ")
        
        # å°è¯•å¯ç”¨æ•°æ®åº“ï¼ˆä½¿ç”¨æ­£ç¡®çš„å¯†ç ï¼‰
        db_config = {
            'password': '12345'  # ä½¿ç”¨ä½ çš„æ•°æ®åº“å¯†ç 
        }
        if workflow.enable_database(db_config):
            print("âœ… æ•°æ®åº“åŠŸèƒ½å·²å¯ç”¨ï¼Œç¬‘è¯å°†åŒæ—¶ä¿å­˜åˆ°æ•°æ®åº“å’ŒCSV")
        else:
            print("âš ï¸ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œå°†ä»…ä¿å­˜åˆ°CSVæ–‡ä»¶")
        
        # æµ‹è¯•é…ç½®
        test_config = {
            'total_target': 5000,  # ç”Ÿæˆ1000æ¡ç¬‘è¯
            'batch_size': 10,
            'joke_categories': [
                'å“²å­¦æ—¥å¸¸æ¢—', 'ç§‘å­¦åŒå…³æ¢—', 'é€»è¾‘ç”Ÿæ´»æ¢—', 
                'æ–‡å­—æ¸¸æˆæ¢—', 'ç”Ÿæ´»ç§‘å­¦æ¢—', 'åå·®å¹½é»˜æ¢—'
            ],
            'database_enabled': False,  # å¯ç”¨æ•°æ®åº“åŠŸèƒ½
            'csv_output': {
                'enabled': True,
                'output_dir': 'workspace/joke_output',
                'filename': 'jokes_batch_output.csv',
                'encoding': 'utf-8-sig'
            }
        }
        
        print(f"ğŸ“Š æµ‹è¯•é…ç½®: {test_config}")
        
        # åˆ›å»ºæ¨¡æ‹ŸèŠå¤©ç•Œé¢
        mock_chat = MockWorkflowChat()
        
        # åˆ›å»ºå·¥ä½œæµå›¾
        graph = await workflow.create_joke_graph()
        compiled_graph = graph.compile()
        print("âœ… å·¥ä½œæµå›¾åˆ›å»ºå®Œæˆ")
        
        # å‡†å¤‡è¾“å…¥æ•°æ®
        input_data = {
            'config': test_config,
            'batch_size': test_config['batch_size'],
            'total_target': test_config['total_target'],
            'joke_categories': test_config['joke_categories'],
            'difficulty_levels': ['ç®€å•', 'ä¸­ç­‰', 'å¤æ‚'],
            'humor_styles': ['å†·å¹½é»˜', 'è‡ªå˜²', 'è§‚å¯Ÿå¼', 'åå·®èŒ'],
            'pg_config': {},
            'workflow_chat': mock_chat,
            'llm': llm
        }
        
        print("\nğŸš€ å¼€å§‹æ‰§è¡Œç¬‘è¯ç”Ÿæˆå·¥ä½œæµ...")
        
        # æ‰§è¡Œå·¥ä½œæµ
        final_result = None
        async for result in compiled_graph.stream(input_data):
            if result:
                final_result = result
        
        # æ˜¾ç¤ºç»“æœ
        if final_result:
            print("\nâœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ!")
            
            generated_jokes = final_result.get('generated_jokes', [])
            print(f"ğŸ“ ç”Ÿæˆç¬‘è¯æ•°é‡: {len(generated_jokes)}")
            
            if generated_jokes:
                print("\nğŸ­ ç”Ÿæˆçš„ç¬‘è¯ç¤ºä¾‹:")
                for i, joke in enumerate(generated_jokes[:5], 1):  # æ˜¾ç¤ºå‰5æ¡
                    print(f"\n--- ç¬‘è¯ {i} ---")
                    print(f"å…³é”®è¯: {joke.get('å…³é”®è¯', 'N/A')}")
                    print(f"å†…å®¹: {joke.get('ç¬‘è¯å†…å®¹', 'N/A')}")
                    print("-" * 50)
                
                # æ˜¾ç¤ºCSVä¿å­˜ç»“æœ
                csv_result = final_result.get('csv_save_result', {})
                if csv_result.get('success'):
                    csv_file = csv_result.get('file_path', 'æœªçŸ¥')
                    print(f"\nğŸ’¾ CSVç»“æœå·²ä¿å­˜åˆ°: {csv_file}")
                else:
                    print(f"\nâš ï¸ CSVä¿å­˜å¤±è´¥: {csv_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
                # é¢å¤–ä¿å­˜JSONå¤‡ä»½
                import json
                from datetime import datetime
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_file = f"workspace/joke_output/backup_jokes_{timestamp}.json"
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(backup_file), exist_ok=True)
                
                with open(backup_file, 'w', encoding='utf-8') as f:
                    json.dump({
                        'config': test_config,
                        'generated_jokes': generated_jokes,
                        'total_count': len(generated_jokes),
                        'timestamp': timestamp,
                        'csv_save_result': csv_result
                    }, f, ensure_ascii=False, indent=2)
                
                print(f"ğŸ’¾ JSONå¤‡ä»½å·²ä¿å­˜åˆ°: {backup_file}")
            
            else:
                print("âš ï¸ æ²¡æœ‰ç”Ÿæˆç¬‘è¯ï¼ˆå¯èƒ½æ˜¯APIå¯†é’¥æ— æ•ˆæˆ–ç½‘ç»œé—®é¢˜ï¼‰")
        
        else:
            print("âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥")
    
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    """ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶è¿›è¡Œæœ¬åœ°æµ‹è¯•"""
    print("ğŸ­ æ–¹çŸ¥è¡¡ç¬‘è¯ç”Ÿæˆå·¥ä½œæµ - æœ¬åœ°æµ‹è¯•æ¨¡å¼")
    print("=" * 60)
    
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(main())