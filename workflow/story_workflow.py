"""
å‰§æƒ…ç”Ÿæˆå·¥ä½œæµ - åŸºäºGraph+Nodeçš„å‰§æƒ…åˆ›ä½œç³»ç»Ÿ
é›†æˆè§’è‰²åº“ã€åœ°ç‚¹åº“ã€å‰§æƒ…ç”Ÿæˆç­‰åŠŸèƒ½
"""

import json
import asyncio
import csv
import random
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from core.graph import StateGraph
from core.base import BaseNode
from llm.base import LLMFactory
from core.types import LLMConfig, TaskResult, Message, MessageRole

logger = logging.getLogger(__name__)

class StoryWorkflow:
    """å‰§æƒ…ç”Ÿæˆå·¥ä½œæµç®¡ç†å™¨"""
    
    def __init__(self, llm=None):
        self.llm = llm
        self.graph = None
        self.characters_data = {}
        self.locations_data = {}
        self.protagonist_data = ""  # ä¸»è§’æ–¹çŸ¥è¡¡çš„è¯¦ç»†äººè®¾
        self.current_config = {
            'protagonist': 'æ–¹çŸ¥è¡¡',  # å›ºå®šä¸»è§’
            'selected_characters': [],
            'selected_locations': [],
            'story_type': 'daily_life',  # daily_life, romance, adventure, mystery
            'story_length': 'medium',    # short, medium, long
            'relationship_depth': 'casual',  # casual, close, intimate
            'time_setting': 'current',   # current, specific_date
            'mood_tone': 'neutral',      # light, neutral, serious, dramatic
            'interaction_level': 'normal'  # minimal, normal, intensive
        }
        
        # åŠ è½½è§’è‰²ã€åœ°ç‚¹å’Œä¸»è§’æ•°æ®
        self._load_game_data()
        self._load_protagonist_data()
    
    def _load_game_data(self):
        """åŠ è½½æ¸¸æˆè§’è‰²å’Œåœ°ç‚¹æ•°æ®"""
        try:
            # åŠ è½½è§’è‰²æ•°æ®
            char_path = os.path.join(os.path.dirname(__file__), '../../config/yunhub_characters.json')
            if os.path.exists(char_path):
                with open(char_path, 'r', encoding='utf-8') as f:
                    self.characters_data = json.load(f)
                    logger.info(f"æˆåŠŸåŠ è½½è§’è‰²æ•°æ®ï¼ŒåŒ…å« {len(self.characters_data.get('è§’è‰²åˆ—è¡¨', {}))} ä¸ªè§’è‰²")
            
            # åŠ è½½åœ°ç‚¹æ•°æ®
            loc_path = os.path.join(os.path.dirname(__file__), '../../config/yunhub_locations.json')
            if os.path.exists(loc_path):
                with open(loc_path, 'r', encoding='utf-8') as f:
                    self.locations_data = json.load(f)
                    district_count = len(self.locations_data.get("districts", {}))
                    logger.info(f"æˆåŠŸåŠ è½½åœ°ç‚¹æ•°æ®ï¼ŒåŒ…å« {district_count} ä¸ªåŒºåŸŸ")
                    
        except Exception as e:
            logger.error(f"åŠ è½½æ¸¸æˆæ•°æ®å¤±è´¥: {e}")
    
    def _load_protagonist_data(self):
        """åŠ è½½ä¸»è§’æ–¹çŸ¥è¡¡çš„è¯¦ç»†äººè®¾"""
        try:
            protagonist_path = os.path.join(os.path.dirname(__file__), '../../config/åŸºç¡€äººè®¾.txt')
            if os.path.exists(protagonist_path):
                with open(protagonist_path, 'r', encoding='utf-8') as f:
                    self.protagonist_data = f.read()
                    logger.info(f"æˆåŠŸåŠ è½½ä¸»è§’äººè®¾ï¼Œå†…å®¹é•¿åº¦: {len(self.protagonist_data)} å­—ç¬¦")
            else:
                logger.warning("ä¸»è§’äººè®¾æ–‡ä»¶ä¸å­˜åœ¨")
                
        except Exception as e:
            logger.error(f"åŠ è½½ä¸»è§’äººè®¾å¤±è´¥: {e}")
    
    def get_protagonist_info(self) -> Dict[str, Any]:
        """è·å–ä¸»è§’ä¿¡æ¯"""
        return {
            'name': 'æ–¹çŸ¥è¡¡',
            'type': 'protagonist',
            'description': 'å¤§å­¦å¤©æ–‡ç³»æ•™æˆã€ç ”ç©¶å‘˜ï¼Œ28å²ï¼Œç†æ€§ä¸¥è°¨ã€å†…æ•›æ¸©å’Œã€å¹³ç­‰åŒ…å®¹ã€è´£ä»»æ„Ÿå¼º',
            'full_profile': self.protagonist_data
        }
    
    def get_characters_list(self) -> List[Dict[str, Any]]:
        """è·å–è§’è‰²åˆ—è¡¨ï¼ˆä¸åŒ…å«ä¸»è§’ï¼‰"""
        characters = []
        char_list = self.characters_data.get("è§’è‰²åˆ—è¡¨", {})
        
        for name, info in char_list.items():
            # è·³è¿‡ä¸»è§’ï¼Œä¸»è§’å•ç‹¬å¤„ç†
            if name == 'æ–¹çŸ¥è¡¡':
                continue
                
            characters.append({
                'name': name,
                'age': info.get('å¹´é¾„', 'æœªçŸ¥'),
                'personality': info.get('æ€§æ ¼', ''),
                'description': info.get('ç®€ä»‹', ''),
                'locations': info.get('æ´»åŠ¨åœ°ç‚¹', []),
                'plots': info.get('å¯è§¦å‘å‰§æƒ…', []),
                'backstory': info.get('èƒŒæ™¯æ•…äº‹', ''),
                'relationships': info.get('äººé™…å…³ç³»', {}),
                'habits': info.get('ç”Ÿæ´»ä¹ æƒ¯', []),
                'appearance': info.get('å¤–è²Œç‰¹å¾', ''),
                'skills': info.get('ç‰¹é•¿æŠ€èƒ½', [])
            })
        
        return characters
    
    def get_character_details(self, character_name: str) -> Dict[str, Any]:
        """è·å–æŒ‡å®šè§’è‰²çš„è¯¦ç»†ä¿¡æ¯"""
        char_list = self.characters_data.get("è§’è‰²åˆ—è¡¨", {})
        char_info = char_list.get(character_name, {})
        
        if not char_info:
            return {}
            
        return {
            'name': character_name,
            'age': char_info.get('å¹´é¾„', 'æœªçŸ¥'),
            'personality': char_info.get('æ€§æ ¼', ''),
            'description': char_info.get('ç®€ä»‹', ''),
            'backstory': char_info.get('èƒŒæ™¯æ•…äº‹', ''),
            'relationships': char_info.get('äººé™…å…³ç³»', {}),
            'habits': char_info.get('ç”Ÿæ´»ä¹ æƒ¯', []),
            'appearance': char_info.get('å¤–è²Œç‰¹å¾', ''),
            'skills': char_info.get('ç‰¹é•¿æŠ€èƒ½', []),
            'locations': char_info.get('æ´»åŠ¨åœ°ç‚¹', []),
            'plots': char_info.get('å¯è§¦å‘å‰§æƒ…', []),
            'dialogue_style': char_info.get('å¯¹è¯é£æ ¼', ''),
            'motivations': char_info.get('åŠ¨æœºç›®æ ‡', [])
        }
    
    def get_locations_list(self) -> List[Dict[str, Any]]:
        """è·å–åœ°ç‚¹åˆ—è¡¨"""
        locations = []
        districts = self.locations_data.get("districts", {})
        
        for district_name, district_info in districts.items():
            district_locations = district_info.get("locations", {})
            for loc_name, loc_info in district_locations.items():
                locations.append({
                    'name': loc_info.get('name', loc_name),
                    'type': loc_info.get('type', ''),
                    'district': district_info.get('name', district_name),
                    'description': loc_info.get('description', ''),
                    'atmosphere': loc_info.get('atmosphere', ''),
                    'keywords': loc_info.get('keywords', [])
                })
        
        return locations
    
    def update_config(self, config_updates: Dict[str, Any]):
        """æ›´æ–°å·¥ä½œæµé…ç½®"""
        self.current_config.update(config_updates)
    
    async def create_story_graph(self) -> StateGraph:
        """åˆ›å»ºå‰§æƒ…ç”Ÿæˆå›¾å·¥ä½œæµ"""
        self.graph = StateGraph(name="story_generation_workflow")
        
        # åˆ›å»ºèŠ‚ç‚¹
        story_plan_node = StoryPlanningNode()
        plot_generation_node = PlotGenerationNode()
        database_save_node = DatabaseSaveNode()
        
        # æ·»åŠ èŠ‚ç‚¹åˆ°å›¾
        self.graph.add_node("story_planning", story_plan_node)
        self.graph.add_node("plot_generation", plot_generation_node)
        self.graph.add_node("database_save", database_save_node)
        
        # å®šä¹‰èŠ‚ç‚¹è¿æ¥å…³ç³»
        self.graph.add_edge("story_planning", "plot_generation")
        self.graph.add_edge("plot_generation", "database_save")
        
        # è®¾ç½®å…¥å£ç‚¹
        self.graph.set_entry_point("story_planning")
        
        return self.graph
    
    async def execute_story_generation(self, config: Dict[str, Any]) -> TaskResult:
        """æ‰§è¡Œå‰§æƒ…ç”Ÿæˆå·¥ä½œæµ"""
        if not self.graph:
            await self.create_story_graph()
        
        # å‡†å¤‡åˆå§‹è¾“å…¥
        initial_input = {
            'characters_data': self.characters_data,
            'locations_data': self.locations_data,
            'protagonist_data': self.protagonist_data,
            'config': config,
            'protagonist': config.get('protagonist', 'æ–¹çŸ¥è¡¡'),
            'selected_characters': config.get('selected_characters', []),
            'selected_locations': config.get('selected_locations', []),
            'story_count': config.get('story_count', 5),  # å‰§æƒ…æ•°é‡é…ç½®
            'story_type': config.get('story_type', 'daily_life'),
            'story_length': config.get('story_length', 'medium'),
            'relationship_depth': config.get('relationship_depth', 'casual'),
            'time_setting': config.get('time_setting', 'current'),
            'mood_tone': config.get('mood_tone', 'neutral'),
            'interaction_level': config.get('interaction_level', 'normal'),
            'llm': self.llm  # ä¼ é€’LLMå®ä¾‹
        }
        
        # ç¼–è¯‘å¹¶æ‰§è¡Œå›¾å·¥ä½œæµ
        compiled_graph = self.graph.compile()
        result = await compiled_graph.invoke(initial_input)
        
        return result

    async def execute_workflow_stream(self, config: Dict[str, Any], workflow_chat):
        """æµå¼æ‰§è¡Œå·¥ä½œæµ - ä½¿ç”¨StateGraphè‡ªåŠ¨ç¼–æ’"""
        try:
            # å‡†å¤‡åˆå§‹è¾“å…¥
            initial_input = {
                'characters_data': self.characters_data,
                'locations_data': self.locations_data,
                'protagonist_data': self.protagonist_data,  # æ·»åŠ ä¸»è§’å®Œæ•´äººè®¾
                'config': config,
                'protagonist': config.get('protagonist', 'æ–¹çŸ¥è¡¡'),
                'selected_characters': config.get('selected_characters', []),
                'selected_locations': config.get('selected_locations', []),
                'story_count': config.get('story_count', 5),  # å‰§æƒ…æ•°é‡é…ç½®
                'story_type': config.get('story_type', 'daily_life'),
                'story_length': config.get('story_length', 'medium'),
                'relationship_depth': config.get('relationship_depth', 'casual'),
                'time_setting': config.get('time_setting', 'current'),
                'mood_tone': config.get('mood_tone', 'neutral'),
                'interaction_level': config.get('interaction_level', 'normal'),
                'workflow_chat': workflow_chat,  # ä¼ é€’UIæ›´æ–°å™¨
                'llm': self.llm  # ä¼ é€’LLMå®ä¾‹
            }
            
            # åˆ›å»ºå¹¶ç¼–è¯‘å›¾å·¥ä½œæµ
            if not self.graph:
                await self.create_story_graph()
            
            compiled_graph = self.graph.compile()
            
            # ä½¿ç”¨å›¾çš„æµå¼æ‰§è¡Œ
            async for stream_event in compiled_graph.stream(initial_input):
                event_type = stream_event.get('type')
                node_name = stream_event.get('node')
                
                if event_type == 'start':
                    # å·¥ä½œæµå¼€å§‹
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "å·¥ä½œæµå¼€å§‹æ‰§è¡Œ...",
                        False
                    )
                
                elif event_type == 'node_start':
                    # èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ
                    node_display_name = self._get_node_display_name(node_name)
                    workflow_chat.current_node = self._get_node_id(node_name)
                    
                    yield (
                        workflow_chat.update_node_state(self._get_node_id(node_name), "active"),
                        "",
                        f"{node_display_name}å¼€å§‹æ‰§è¡Œ...",
                        False
                    )
                
                elif event_type == 'node_streaming':
                    # èŠ‚ç‚¹æµå¼æ‰§è¡Œä¸­ - å®æ—¶æ›´æ–°UIæ˜¾ç¤ºè¿›åº¦
                    intermediate_result = stream_event.get('intermediate_result')
                    if intermediate_result and intermediate_result.state_update:
                        # è·å–å½“å‰ç”Ÿæˆçš„å†…å®¹é•¿åº¦
                        content_length = 0
                        for key in ['planning_result', 'plot_content']:
                            if key in intermediate_result.state_update:
                                content_length = len(intermediate_result.state_update[key])
                                break
                        
                        # å®æ—¶æ›´æ–°è¿›åº¦ä¿¡æ¯ - é‡è¦ï¼šè·å–æœ€æ–°çš„è¿›åº¦HTMLï¼Œå› ä¸ºèŠ‚ç‚¹å†…éƒ¨å·²ç»æ›´æ–°äº†ç»“æœ
                        if content_length > 0:
                            yield (
                                workflow_chat._create_workflow_progress(),  # è¿™ä¸ªä¼šåŒ…å«èŠ‚ç‚¹å†…éƒ¨æ›´æ–°çš„æœ€æ–°å†…å®¹
                                "",  # å¿«æ·å›å¤åŒºåŸŸä¿æŒç©º
                                f"æ­£åœ¨ç”Ÿæˆå†…å®¹... å½“å‰é•¿åº¦: {content_length} å­—ç¬¦",
                                False  # å‘é€æŒ‰é’®ä¿æŒç¦ç”¨
                            )
                
                elif event_type == 'node_complete':
                    # èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ
                    node_display_name = self._get_node_display_name(node_name)
                    
                    yield (
                        workflow_chat.update_node_state(self._get_node_id(node_name), "completed"),
                        "",
                        f"{node_display_name}æ‰§è¡Œå®Œæˆ",
                        False
                    )
                
                elif event_type == 'node_error':
                    # èŠ‚ç‚¹æ‰§è¡Œé”™è¯¯
                    error_msg = stream_event.get('error', 'æœªçŸ¥é”™è¯¯')
                    
                    await workflow_chat.add_node_message(
                        "ç³»ç»Ÿ",
                        f"èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {error_msg}",
                        "error"
                    )
                    
                    yield (
                        workflow_chat.update_node_state(self._get_node_id(node_name), "error"),
                        "",
                        "",
                        False
                    )
                
                elif event_type == 'final':
                    # å·¥ä½œæµå®Œæˆ
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "å·¥ä½œæµæ‰§è¡Œå®Œæˆ",
                        False
                    )
                
                # å…¶ä»–äº‹ä»¶ç±»å‹å¯ä»¥å¿½ç•¥æˆ–è®°å½•æ—¥å¿—
                else:
                    # æŒç»­æ›´æ–°UIä»¥ä¿æŒæµç•…æ€§
                    yield (
                        workflow_chat._create_workflow_progress(),
                        "",
                        "å·¥ä½œæµæ‰§è¡Œä¸­...",
                        False
                    )
                
        except Exception as e:
            logger.error(f"å·¥ä½œæµæµå¼æ‰§è¡Œå¤±è´¥: {e}")
            await workflow_chat.add_node_message(
                "ç³»ç»Ÿ",
                f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}",
                "error"
            )
            yield (
                workflow_chat.update_node_state("planning", "error"),
                "",
                "",
                False
            )
    
    def _get_node_display_name(self, node_name: str) -> str:
        """è·å–èŠ‚ç‚¹æ˜¾ç¤ºåç§°"""
        name_mapping = {
            'story_planning': 'å‰§æƒ…è§„åˆ’',
            'plot_generation': 'å‰§æƒ…ç”Ÿæˆ',
            'database_save': 'æ•°æ®åº“ä¿å­˜'
        }
        return name_mapping.get(node_name, node_name)
    
    def _get_node_id(self, node_name: str) -> str:
        """è·å–èŠ‚ç‚¹ID"""
        id_mapping = {
            'story_planning': 'planning',
            'plot_generation': 'plot', 
            'database_save': 'save'
        }
        return id_mapping.get(node_name, node_name)


class StoryPlanningNode(BaseNode):
    """å‰§æƒ…è§„åˆ’èŠ‚ç‚¹ - åˆ†æè§’è‰²å…³ç³»å’Œæ•…äº‹å¤§çº²"""
    
    def __init__(self):
        super().__init__(name="story_planning", stream=True)
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå‰§æƒ…è§„åˆ’èŠ‚ç‚¹ - éæµå¼ç‰ˆæœ¬"""
        # ä½¿ç”¨æµå¼æ‰§è¡Œå¹¶è¿”å›æœ€ç»ˆç»“æœ
        final_result = None
        async for result in self.execute_stream(input_data):
            final_result = result
        return final_result or input_data
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œå‰§æƒ…è§„åˆ’èŠ‚ç‚¹"""
        print("ğŸ¯ å¼€å§‹å‰§æƒ…è§„åˆ’...")
        
        workflow_chat = input_data.get('workflow_chat')
        llm = input_data.get('llm')
        
        # è·å–æ‰€æœ‰é…ç½®å‚æ•°
        protagonist_data = input_data.get('protagonist_data', '')
        characters_data = input_data.get('characters_data', {})
        locations_data = input_data.get('locations_data', {})
        selected_characters = input_data.get('selected_characters', [])
        selected_locations = input_data.get('selected_locations', [])
        story_count = input_data.get('story_count', 5)  # å‰§æƒ…æ•°é‡
        story_type = input_data.get('story_type', 'daily_life')
        story_length = input_data.get('story_length', 'medium')
        relationship_depth = input_data.get('relationship_depth', 'casual')
        
        # æ›´æ–°UI - å¼€å§‹çŠ¶æ€
        if workflow_chat:
            await workflow_chat.add_node_message(
                "å‰§æƒ…è§„åˆ’",
                "æ­£åœ¨æŸ¥è¯¢ç°æœ‰å‰§æƒ…ï¼Œåˆ†æä¸»è§’æ–¹çŸ¥è¡¡ä¸é€‰å®šè§’è‰²çš„å…³ç³»ï¼Œç”Ÿæˆå‰§æƒ…æ¡†æ¶...",
                "progress"
            )
        
        # è·å–å·²æœ‰å‰§æƒ…ä½œä¸ºå‚è€ƒ
        existing_stories_summary = {}
        existing_story_ids = []
        max_story_number = 0
        try:
            from database import story_manager
            
            # æŸ¥è¯¢æ‰€æœ‰é€‰ä¸­è§’è‰²çš„å·²æœ‰å‰§æƒ…
            all_characters = ['æ–¹çŸ¥è¡¡'] + selected_characters
            existing_stories_summary = story_manager.get_character_existing_stories_summary(all_characters)
            
            # è·å–æ‰€æœ‰ç°æœ‰çš„æ•…äº‹IDï¼Œç”¨äºé¿å…é‡å¤
            all_stories = story_manager.get_stories_by_filter({}, limit=1000)
            existing_story_ids = [story['story_id'] for story in all_stories]
            
            # åˆ†æç°æœ‰IDæ¨¡å¼ï¼Œæ‰¾å‡ºæœ€å¤§ç¼–å·
            import re
            story_numbers = []
            for story_id in existing_story_ids:
                # åŒ¹é…STORY_XXXæ ¼å¼çš„ID
                match = re.match(r'STORY_(\d+)', story_id)
                if match:
                    story_numbers.append(int(match.group(1)))
            
            max_story_number = max(story_numbers) if story_numbers else 0
            
            existing_count = existing_stories_summary.get('total_stories', 0)
            if workflow_chat and existing_count > 0:
                await workflow_chat.add_node_message(
                    "å‰§æƒ…è§„åˆ’",
                    f"å·²æ‰¾åˆ° {existing_count} ä¸ªç›¸å…³å‰§æƒ…ä½œä¸ºå‚è€ƒï¼Œç°æœ‰æœ€å¤§æ•…äº‹ç¼–å·: {max_story_number}ï¼Œæ­£åœ¨åˆ†æå‰§æƒ…é£æ ¼å’Œä¸»é¢˜...",
                    "progress"
                )
                
        except Exception as e:
            logger.warning(f"è·å–å·²æœ‰å‰§æƒ…å¤±è´¥ï¼Œå°†ä¸ä½¿ç”¨å†å²å‚è€ƒ: {e}")
            existing_stories_summary = {
                'existing_stories': [],
                'story_themes': [],
                'character_relationships': {},
                'common_locations': [],
                'story_styles': []
            }
            existing_story_ids = []
            max_story_number = 0
        
        # æ„å»ºè¯¦ç»†çš„è§’è‰²ä¿¡æ¯
        character_details = []
        char_list = characters_data.get("è§’è‰²åˆ—è¡¨", {})
        for char_name in selected_characters:
            if char_name in char_list:
                char_info = char_list[char_name]
                detail = f"""
## {char_name}

- å¹´é¾„ï¼š{char_info.get('å¹´é¾„', 'æœªçŸ¥')}
- æ€§æ ¼ï¼š{char_info.get('æ€§æ ¼', '')}
- ç®€ä»‹ï¼š{char_info.get('ç®€ä»‹', '')}
- èƒŒæ™¯æ•…äº‹ï¼š{char_info.get('èƒŒæ™¯æ•…äº‹', '')}
- æ´»åŠ¨åœ°ç‚¹ï¼š{', '.join(char_info.get('æ´»åŠ¨åœ°ç‚¹', []))}
- äººé™…å…³ç³»ï¼š{char_info.get('äººé™…å…³ç³»', {})}
- å¯è§¦å‘å‰§æƒ…ï¼š{', '.join(char_info.get('å¯è§¦å‘å‰§æƒ…', []))}
"""
                character_details.append(detail)
        
        # æ„å»ºè¯¦ç»†çš„åœ°ç‚¹ä¿¡æ¯
        location_details = []
        districts = locations_data.get("districts", {})
        for loc_name in selected_locations:
            for district_name, district_info in districts.items():
                locations = district_info.get("locations", {})
                for location_key, location_info in locations.items():
                    if location_info.get('name') == loc_name or location_key == loc_name:
                        detail = f"""
## {location_info.get('name', loc_name)}ï¼ˆ{district_info.get('name', district_name)}åŒºï¼‰

- ç±»å‹ï¼š{location_info.get('type', '')}
- æè¿°ï¼š{location_info.get('description', '')}
- æ°›å›´ï¼š{location_info.get('atmosphere', '')}
- å…³é”®è¯ï¼š{', '.join(location_info.get('keywords', []))}
"""
                        location_details.append(detail)
        
        # æ„å»ºå·²æœ‰å‰§æƒ…å‚è€ƒä¿¡æ¯
        existing_stories_info = ""
        if existing_stories_summary.get('existing_stories'):
            existing_stories_info = f"""
# å·²æœ‰å‰§æƒ…å‚è€ƒï¼ˆé¿å…é‡å¤ï¼‰

## å·²æœ‰å‰§æƒ…åˆ—è¡¨ï¼ˆå…± {existing_stories_summary.get('total_stories', 0)} ä¸ªï¼‰

{chr(10).join([f"- {story.get('story_id', 'N/A')}: {story.get('story_overview', story.get('main_conflict', 'N/A'))}" for story in existing_stories_summary['existing_stories'][:10]])}

## å·²æœ‰æ•…äº‹IDä¿¡æ¯

ç°æœ‰æ•…äº‹ID: {', '.join(existing_story_ids[:20])}{'...' if len(existing_story_ids) > 20 else ''}
æœ€å¤§æ•…äº‹ç¼–å·: {max_story_number}

**é‡è¦è¦æ±‚**ï¼š
1. è¯·é¿å…ä¸å·²æœ‰å‰§æƒ…å†…å®¹é‡å¤ï¼Œåˆ›ä½œæ–°çš„å‰§æƒ…
2. æ–°ç”Ÿæˆçš„æ•…äº‹IDå¿…é¡»ä» STORY_{max_story_number + 1:03d} å¼€å§‹é€’å¢ï¼Œé¿å…ä¸ç°æœ‰IDé‡å¤
"""
        else:
            existing_stories_info = f"# é¦–æ¬¡åˆ›ä½œï¼ˆæ— å·²æœ‰å‰§æƒ…å‚è€ƒï¼‰\n\nå½“å‰æœ€å¤§æ•…äº‹ç¼–å·: {max_story_number}\næ–°æ•…äº‹IDå°†ä» STORY_{max_story_number + 1:03d} å¼€å§‹"

        # æ„å»ºé€šç”¨çš„å‰§æƒ…è§„åˆ’æç¤ºè¯
        planning_prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„å‰§æƒ…ç­–åˆ’å¸ˆï¼Œéœ€è¦åŸºäºä»¥ä¸‹ä¿¡æ¯åˆ¶å®šå‰§æƒ…è§„åˆ’æ¡†æ¶ï¼š

# ä¸»è§’è®¾å®š

{protagonist_data}

# å‚ä¸è§’è‰²ä¿¡æ¯

{''.join(character_details) if character_details else 'æ— å…¶ä»–è§’è‰²å‚ä¸'}

# åœ°ç‚¹ä¿¡æ¯

{''.join(location_details) if location_details else 'æ— ç‰¹å®šåœ°ç‚¹é™åˆ¶'}

{existing_stories_info}

# å‰§æƒ…é…ç½®

- å‰§æƒ…æ•°é‡ï¼š{story_count} ä¸ªå¤§å‰§æƒ…
- å‰§æƒ…ç±»å‹ï¼š{story_type}
- å‰§æƒ…ç»†åˆ†ç¨‹åº¦ï¼š{story_length}ï¼ˆæ¯ä¸ªå‰§æƒ…åŒ…å«çš„ç‹¬ç«‹å°èŠ‚æ•°é‡ï¼‰
- å…³ç³»æ·±åº¦ï¼š{relationship_depth}

**é‡è¦è¦æ±‚**ï¼š
1. æ¯ä¸ªå°èŠ‚éƒ½æ˜¯ç‹¬ç«‹çš„ä¸€å¹•æ¼”ç»ï¼Œä¸èƒ½æœ‰æ—¶é—´æˆ–ç©ºé—´çš„è¿ç»­æ€§ï¼Œåº”è¯¥æ˜¯ä¸åŒå¤©æ•°çš„æ•…äº‹ï¼Œä½†æ˜¯æ³¨æ„å†…å®¹ç¦æ­¢å‡ºç°æ—¥çº§åˆ«çš„æ—¶é—´æ¯”å¦‚å‘¨å…­ï¼Œæ˜ŸæœŸå‡ è¿™ç§æè¿°
2. è¿™äº›å°èŠ‚ä¼šè¢«åˆ†å¸ƒåˆ°ä»»æ„æ—¶é—´åœ°ç‚¹ä½¿ç”¨ï¼Œå¿…é¡»å®Œå…¨ç‹¬ç«‹
3. æ¯ä¸ªå°èŠ‚å¿…é¡»åŒ…å«å®Œæ•´çš„å››å¹•å¼ç»“æ„ï¼ˆå¼€ç«¯â†’å‘å±•â†’é«˜æ½®â†’ç»“å±€ï¼‰
4. æ¯ä¸ªå°èŠ‚éƒ½å¿…é¡»å‡ºç°ä¸»è§’æ–¹çŸ¥è¡¡å’ŒæŒ‡å®šçš„å‚ä¸è§’è‰²

# è¾“å‡ºè¦æ±‚

è¯·ä»¥JSONæ ¼å¼è¾“å‡º **{story_count} ä¸ªå®Œæ•´å¤§å‰§æƒ…** çš„è§„åˆ’æ¡†æ¶ï¼Œé‡ç‚¹å…³æ³¨ç‹¬ç«‹å°èŠ‚çš„è®¾è®¡ï¼š

```json
{{
  "planning": {{
    "æ€»ä½“è®¾è®¡": {{
      "å‰§æƒ…æ€»æ•°": {story_count},
      "æ•´ä½“ä¸»é¢˜": "æ‰€æœ‰å‰§æƒ…çš„ç»Ÿä¸€ä¸»é¢˜",
      "è§’è‰²å…³ç³»ç½‘ç»œ": {{
        "ä¸»è§’å…³ç³»å®šä½": {{
          "ä¸è§’è‰²A": "å…·ä½“å…³ç³»å®šä½å’Œå‘å±•è·¯å¾„",
          "ä¸è§’è‰²B": "å…·ä½“å…³ç³»å®šä½å’Œå‘å±•è·¯å¾„"
        }},
        "è§’è‰²é—´å…³ç³»": "ç›¸äº’å…³ç³»å’Œäº’åŠ¨æ¨¡å¼",
        "å…³ç³»å‘å±•è·¯å¾„": "å…³ç³»æ¼”å˜çš„å¯èƒ½æ€§å’Œæ–¹å‘"
      }},
      "åœ°ç‚¹è¿ç”¨ç­–ç•¥": {{
        "åœ°ç‚¹åŠŸèƒ½å®šä½": {{
          "åœ°ç‚¹1": "åœ¨å‰§æƒ…ä¸­çš„åŠŸèƒ½å®šä½å’Œæ°›å›´ä½œç”¨",
          "åœ°ç‚¹2": "åœ¨å‰§æƒ…ä¸­çš„åŠŸèƒ½å®šä½å’Œæ°›å›´ä½œç”¨"
        }},
        "æ°›å›´è¥é€ ": "åœ°ç‚¹æ°›å›´å¦‚ä½•æœåŠ¡äºæƒ…èŠ‚å‘å±•",
        "ç©ºé—´è½¬æ¢æ„ä¹‰": "ç©ºé—´è½¬æ¢çš„å™äº‹ä½œç”¨"
      }}
    }},
    "å‰§æƒ…è§„åˆ’åˆ—è¡¨": [
      {{
        "å‰§æƒ…ID": "STORY_{max_story_number + 1:03d}",
        "å‰§æƒ…åç§°": "ç¬¬1ä¸ªå¤§å‰§æƒ…çš„åç§°",
        "å‰§æƒ…æ¦‚è¿°": "æ•´æ®µå¤§å‰§æƒ…çš„å››å¹•å¼æè¿°ï¼šå¼€ç«¯ï¼ˆèƒŒæ™¯è®¾å®šï¼‰ â†’ å‘å±•ï¼ˆçŸ›ç›¾å‡çº§ï¼‰ â†’ é«˜æ½®ï¼ˆå†²çªé¡¶ç‚¹ï¼‰ â†’ ç»“å±€ï¼ˆé—®é¢˜è§£å†³ï¼‰ï¼Œå®Œæ•´è®²è¿°è¿™ä¸ªå¤§å‰§æƒ…çš„æ•…äº‹è„‰ç»œ",
        "æ•…äº‹ä¸»é¢˜ä¸æ ¸å¿ƒå†²çª": {{
          "æ•…äº‹ä¸»é¢˜": "åŸºäºä¸»è§’æ€§æ ¼ç‰¹å¾å’Œç”Ÿæ´»èƒŒæ™¯ç¡®å®šçš„ä¸»é¢˜ï¼Œé¿å…ä¸å·²æœ‰å‰§æƒ…é‡å¤",
          "æ ¸å¿ƒå†²çª": "ç»“åˆå‚ä¸è§’è‰²è®¾è®¡çš„åˆç†å†²çªç‚¹ï¼Œç¡®ä¿æ–°é¢–æ€§"
        }},
        "ä¸»è¦å‰§æƒ…çº¿": {{
          "å¼€ç«¯": "è®¾å®šèƒŒæ™¯å’Œåˆå§‹æƒ…å†µçš„å…·ä½“æè¿°",
          "å‘å±•": "çŸ›ç›¾é€æ­¥å‡çº§å’Œè§’è‰²äº’åŠ¨çš„è¯¦ç»†è¿‡ç¨‹",
          "é«˜æ½®": "æ ¸å¿ƒå†²çªè¾¾åˆ°é¡¶ç‚¹çš„å…³é”®äº‹ä»¶",
          "ç»“å±€": "é—®é¢˜è§£å†³å’Œè§’è‰²æˆé•¿çš„å®Œæ•´æè¿°"
        }},
        "å…³é”®äº‹ä»¶èŠ‚ç‚¹": [
          {{
            "äº‹ä»¶å": "é‡è¦è½¬æŠ˜ç‚¹æè¿°",
            "è§¦å‘æ¡ä»¶": "å‰ç½®è¦æ±‚å’Œæ¡ä»¶",
            "é¢„æœŸç»“æœ": "å¯¹åç»­å‰§æƒ…çš„å½±å“",
            "é€»è¾‘å…³è”": "ä¸å…¶ä»–äº‹ä»¶çš„é€»è¾‘å…³ç³»"
          }}
        ],
        "æƒ…æ„Ÿå¼ åŠ›è®¾è®¡": {{
          "æƒ…æ„ŸåŸºè°ƒ": "æ ¹æ®é…ç½®çš„mood_toneè®¾è®¡åŸºè°ƒ",
          "æƒ…æ„Ÿèµ·ä¼æ›²çº¿": "æƒ…æ„Ÿå‘å±•çš„å…·ä½“å®‰æ’",
          "è¡¨è¾¾æ–¹å¼": "ç¬¦åˆä¸»è§’æ€§æ ¼çš„æƒ…æ„Ÿè¡¨è¾¾",
          "ç†æ€§æ„Ÿæ€§å¹³è¡¡": "ç†æ€§ä¸æ„Ÿæ€§å†²çªçš„å¤„ç†"
        }}
      }}
    ]
  }}
}}
```

è¯·ç¡®ä¿ï¼š
1. å‡†ç¡®ç”Ÿæˆ **{story_count} ä¸ªå®Œæ•´çš„å¤§å‰§æƒ…è§„åˆ’**
2. æ¯ä¸ªå‰§æƒ…çš„å…³é”®äº‹ä»¶èŠ‚ç‚¹è®¾è®¡è¦è€ƒè™‘ç‹¬ç«‹å°èŠ‚çš„ç‰¹æ€§
3. è§’è‰²å…³ç³»ç½‘ç»œæ¸…æ™°è¯¦ç»†ï¼Œé€‚ç”¨äºæ‰€æœ‰å‰§æƒ…
4. åœ°ç‚¹è¿ç”¨ç­–ç•¥è¦æ”¯æŒç‹¬ç«‹åœºæ™¯çš„è®¾è®¡
5. æƒ…æ„Ÿå¼ åŠ›è®¾è®¡è¦åœ¨å•ä¸ªå°èŠ‚å†…å½¢æˆå®Œæ•´å¼§çº¿
6. æ‰€æœ‰å‰§æƒ…ç›¸äº’ç‹¬ç«‹ï¼Œæ¯ä¸ªå°èŠ‚ä¹Ÿå¿…é¡»ç‹¬ç«‹
7. æ¯ä¸ªå‰§æƒ…éƒ½æœ‰ç‹¬ç‰¹çš„å†²çªç‚¹ï¼Œä½†è¦èƒ½åˆ†è§£ä¸ºç‹¬ç«‹çš„å°èŠ‚æƒ…å¢ƒ
"""
        
        # æµå¼è°ƒç”¨LLM
        if llm:
            try:
                # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
                message = Message(role=MessageRole.USER, content=planning_prompt)
                messages = [message]
                
                logger.info(f"å‰§æƒ…è§„åˆ’: å¼€å§‹æµå¼LLMè°ƒç”¨ï¼Œæç¤ºè¯é•¿åº¦: {len(planning_prompt)}")
                
                # ä½¿ç”¨thinkæ¨¡å¼æµå¼è°ƒç”¨
                chunk_count = 0
                think_content = ""
                final_content = ""
                
                async for chunk_data in llm.stream_generate(
                    messages, 
                    mode="think",
                    return_dict=True
                ):
                    chunk_count += 1
                    
                    think_part = chunk_data.get("think", "")
                    content_part = chunk_data.get("content", "")
                    
                    think_content += think_part
                    final_content += content_part
                    
                    # å®æ—¶æ›´æ–°UI
                    if workflow_chat:
                        try:
                            display_content = ""
                            if think_content.strip():
                                display_content += f"""
<div style="background: #f8f9fa; border-left: 4px solid #6c757d; padding: 10px; margin: 10px 0; border-radius: 4px;">
æ€è€ƒè¿‡ç¨‹ï¼š<br>
{think_content}
</div>"""
                            
                            if final_content.strip():
                                display_content += f"""
<div style="background: #e8f5e9; border-left: 4px solid #28a745; padding: 10px; margin: 10px 0; border-radius: 4px;">
è§„åˆ’ç»“æœï¼š<br>
{final_content}
</div>"""
                            
                            await workflow_chat.add_node_message(
                                "å‰§æƒ…è§„åˆ’",
                                display_content,
                                "streaming"
                            )
                        except Exception as ui_error:
                            logger.warning(f"å‰§æƒ…è§„åˆ’UIæ›´æ–°å¤±è´¥: {ui_error}")
                    
                    # æ¯ä¸ªchunkéƒ½yield
                    yield {
                        'planning_result': final_content,
                        'planning_think': think_content,
                        'chunk_progress': f"{chunk_count} chunks processed"
                    }
                
                logger.info(f"å‰§æƒ…è§„åˆ’: æµå¼ç”Ÿæˆå®Œæˆï¼Œæ€»chunkæ•°: {chunk_count}ï¼Œå†…å®¹é•¿åº¦: {len(final_content)}")
                        
            except Exception as e:
                error_msg = f"å‰§æƒ…è§„åˆ’LLMè°ƒç”¨å¤±è´¥: {type(e).__name__}: {str(e)}"
                logger.error(error_msg, exc_info=True)
                raise Exception(error_msg)
        else:
            error_msg = "å‰§æƒ…è§„åˆ’: LLMæœªåˆå§‹åŒ–"
            logger.error(error_msg)
            raise Exception(error_msg)
        
        # è§£æJSONæ ¼å¼çš„ç»“æœ
        try:
            from parsers.json_parser import JSONParser
            parser = JSONParser()
            
            json_content = self._extract_json_from_content(final_content)
            parsed_result = parser.parse(json_content)
            
            if parsed_result and 'planning' in parsed_result:
                planning_data = parsed_result['planning']
                logger.info(f"æˆåŠŸè§£æå‰§æƒ…è§„åˆ’JSONç»“æœ")
            else:
                # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹ä½œä¸ºå¤‡é€‰
                planning_data = final_content
                logger.warning(f"å‰§æƒ…è§„åˆ’JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
                
        except Exception as parse_error:
            logger.warning(f"å‰§æƒ…è§„åˆ’JSONè§£æå¼‚å¸¸: {parse_error}ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
            planning_data = final_content
        
        # æœ€ç»ˆå®Œæ•´ç»“æœ
        output_data = input_data.copy()
        output_data['planning_result'] = planning_data
        
        print(f"âœ… å‰§æƒ…è§„åˆ’å®Œæˆ")
        yield output_data
    
    def _extract_json_from_content(self, content: str) -> str:
        """ä»ç”Ÿæˆå†…å®¹ä¸­æå–JSONéƒ¨åˆ†"""
        import re
        
        # æŸ¥æ‰¾```json...```ä»£ç å—
        json_pattern = r'```json\s*(.*?)\s*```'
        matches = re.findall(json_pattern, content, re.DOTALL | re.IGNORECASE)
        
        if matches:
            return matches[0].strip()
        
        # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•æŸ¥æ‰¾ä»¥{å¼€å¤´}ç»“å°¾çš„å†…å®¹
        json_pattern2 = r'\{.*\}'
        matches2 = re.findall(json_pattern2, content, re.DOTALL)
        
        if matches2:
            return matches2[0].strip()
        
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›åŸå†…å®¹
        return content.strip()


class PlotGenerationNode(BaseNode):
    """å‰§æƒ…ç”ŸæˆèŠ‚ç‚¹ - ç”Ÿæˆå…·ä½“çš„å‰§æƒ…äº‹ä»¶"""
    
    def __init__(self):
        super().__init__(name="plot_generation", stream=True)
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå‰§æƒ…ç”ŸæˆèŠ‚ç‚¹ - éæµå¼ç‰ˆæœ¬"""
        # ä½¿ç”¨æµå¼æ‰§è¡Œå¹¶è¿”å›æœ€ç»ˆç»“æœ
        final_result = None
        async for result in self.execute_stream(input_data):
            final_result = result
        return final_result or input_data
    
    async def execute_stream(self, input_data: Dict[str, Any]):
        """æµå¼æ‰§è¡Œå‰§æƒ…ç”ŸæˆèŠ‚ç‚¹"""
        print("ğŸ“š å¼€å§‹ç”Ÿæˆå‰§æƒ…...")
        
        workflow_chat = input_data.get('workflow_chat')
        llm = input_data.get('llm')
        planning_result = input_data.get('planning_result', '')
        
        # éªŒè¯è§„åˆ’ç»“æœ
        if not planning_result or not planning_result.strip():
            error_msg = f"å‰§æƒ…ç”Ÿæˆå¤±è´¥ï¼šç¼ºå°‘å‰§æƒ…è§„åˆ’ç»“æœã€‚input_dataé”®: {list(input_data.keys())}"
            logger.error(error_msg)
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "å‰§æƒ…ç”Ÿæˆ",
                    error_msg,
                    "error"
                )
            raise Exception(error_msg)
        
        # æ›´æ–°UI - å¼€å§‹çŠ¶æ€
        if workflow_chat:
            await workflow_chat.add_node_message(
                "å‰§æƒ…ç”Ÿæˆ", 
                f"æ­£åœ¨åŸºäºè§„åˆ’ç»“æœç”Ÿæˆå…·ä½“å‰§æƒ…ï¼ˆè§„åˆ’é•¿åº¦ï¼š{len(planning_result)} å­—ç¬¦ï¼‰...",
                "progress"
            )
        
        # è·å–å®Œæ•´çš„é…ç½®å’Œè§„åˆ’ç»“æœï¼ˆå…ˆè·å–å˜é‡ï¼‰
        protagonist_data = input_data.get('protagonist_data', '')
        characters_data = input_data.get('characters_data', {})
        selected_characters = input_data.get('selected_characters', [])
        selected_locations = input_data.get('selected_locations', [])
        story_count = input_data.get('story_count', 5)
        story_type = input_data.get('story_type', 'daily_life')
        story_length = input_data.get('story_length', 'medium')
        relationship_depth = input_data.get('relationship_depth', 'casual')
        
        # è·å–ç°æœ‰æ•…äº‹IDä¿¡æ¯ï¼Œç¡®ä¿ç”Ÿæˆçš„IDä¸é‡å¤
        existing_story_ids = []
        max_story_number = 0
        try:
            from database import story_manager
            all_stories = story_manager.get_stories_by_filter({}, limit=1000)
            existing_story_ids = [story['story_id'] for story in all_stories]
            
            # ç”Ÿæˆä¸´æ—¶IDå‰ç¼€ï¼Œå®é™…å­˜å‚¨æ—¶ä¼šè¢«æ›¿æ¢ä¸ºæ•°æ®åº“è‡ªå¢ID
            temp_prefix = "TEMP_"
            
        except Exception as e:
            logger.warning(f"è·å–ç°æœ‰æ•…äº‹IDå¤±è´¥: {e}")
            existing_story_ids = []
            temp_prefix = "TEMP_"
        
        # æ„å»ºé€šç”¨çš„å‰§æƒ…ç”Ÿæˆæç¤ºè¯
        plot_prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„å‰§æƒ…ç¼–å‰§ï¼Œéœ€è¦åŸºäºå‰§æƒ…è§„åˆ’ç”Ÿæˆå…·ä½“çš„å‰§æƒ…å†…å®¹ã€‚

# å‰§æƒ…è§„åˆ’

{planning_result}

# è§’è‰²è®¾å®š

{protagonist_data}

# å‰§æƒ…é…ç½®

- å‰§æƒ…æ•°é‡ï¼š{story_count} ä¸ªå¤§å‰§æƒ…
- å‰§æƒ…ç±»å‹ï¼š{story_type}
- å‰§æƒ…ç»†åˆ†ç¨‹åº¦ï¼š{story_length}ï¼ˆæ¯ä¸ªå‰§æƒ…åŒ…å«çš„ç‹¬ç«‹å°èŠ‚æ•°é‡ï¼‰
- å…³ç³»æ·±åº¦ï¼š{relationship_depth}

# å‰§æƒ…IDç”Ÿæˆè¯´æ˜

- ä½¿ç”¨ä¸´æ—¶IDï¼Œæ ¼å¼ä¸º TEMP_001, TEMP_002 ç­‰
- æ•°æ®åº“ä¿å­˜æ—¶ä¼šè‡ªåŠ¨åˆ†é…çœŸæ­£çš„ID

**æ ¸å¿ƒè¦æ±‚**ï¼š
1. æ¯ä¸ªå°èŠ‚éƒ½æ˜¯ç‹¬ç«‹çš„ä¸€å¹•æ¼”ç»ï¼ŒåŒ…å«å®Œæ•´çš„å››å¹•å¼ç»“æ„
2. æ¯ä¸ªå°èŠ‚å¿…é¡»åŒæ—¶å‡ºç°ä¸»è§’æ–¹çŸ¥è¡¡å’ŒæŒ‡å®šçš„å‚ä¸è§’è‰²
3. å°èŠ‚ä¹‹é—´æ²¡æœ‰æ—¶é—´ç©ºé—´è”ç³»ï¼Œå¯ä»¥åœ¨ä»»æ„æ—¶é—´åœ°ç‚¹ä½¿ç”¨
4. æ¯ä¸ªå°èŠ‚éƒ½æœ‰å¼€ç«¯â†’å‘å±•â†’é«˜æ½®â†’ç»“å±€çš„å®Œæ•´æˆå‰§å¼§çº¿
5. **æ•…äº‹ä½¿ç”¨ä¸´æ—¶IDï¼Œæ•°æ®åº“ä¼šè‡ªåŠ¨æ›¿æ¢ä¸ºçœŸæ­£çš„ID**

# è¾“å‡ºè¦æ±‚

è¯·åŸºäºè§„åˆ’ä¸­çš„ **{story_count} ä¸ªå¤§å‰§æƒ…**ï¼Œä»¥JSONæ ¼å¼è¾“å‡ºä¸°å¯Œçš„ç‹¬ç«‹å°èŠ‚å†…å®¹ï¼š

```json
{{
  "story": {{
    "æ€»ä½“ä¿¡æ¯": {{
      "å‰§æƒ…æ€»æ•°": {story_count},
      "ç”Ÿæˆæ—¶é—´": "{{ç”Ÿæˆæ—¶é—´}}",
      "ä¸»è§’": "æ–¹çŸ¥è¡¡"
    }},
    "å‰§æƒ…åˆ—è¡¨": [
      {{
        "å‰§æƒ…ID": "TEMP_001",
        "å‰§æƒ…åç§°": "ç¬¬1ä¸ªå¤§å‰§æƒ…çš„åç§°",
        "å‰§æƒ…æ¦‚è¿°": "æ•´æ®µå¤§å‰§æƒ…çš„å››å¹•å¼æ¦‚è¿°ï¼Œæ¸…æ™°æè¿°ä»å¼€ç«¯åˆ°ç»“å±€çš„å®Œæ•´æ•…äº‹å¼§çº¿",
        "å‰§æƒ…å°èŠ‚": [
          {{
            "å°èŠ‚ID": "STEMP_001_SCENE_001",
            "å°èŠ‚æ ‡é¢˜": "ç‹¬ç«‹å°èŠ‚çš„æ ‡é¢˜",
            "å°èŠ‚å†…å®¹": "å®Œæ•´çš„æ•…äº‹å†…å®¹ï¼Œè‡ªç„¶èå…¥å››å¹•å¼ç»“æ„ï¼ˆå¼€ç«¯â†’å‘å±•â†’é«˜æ½®â†’ç»“å±€ï¼‰ï¼ŒåŒ…å«è§’è‰²å¯¹è¯å’Œæƒ…æ„Ÿå˜åŒ–ï¼Œä½“ç°ç‹¬ç«‹å®Œæ•´çš„ä¸€å¹•æ¼”ç»ï¼Œç¦æ­¢åŒ…å«æ—¶é—´ï¼Œä¸»è§’è¯´è¯è¦æ­£å¸¸åˆç†çš„äººè®¾è¯­æ°”ï¼Œç¦æ­¢è£…é€¼",
            "åœ°ç‚¹": "å‘ç”Ÿåœ°ç‚¹",
            "å‚ä¸è§’è‰²": ["æ–¹çŸ¥è¡¡", "æŒ‡å®šè§’è‰²å"]
          }}
        ],
        "å‰§æƒ…æ€»ç»“": {{
          "ä¸»è¦å†²çª": "æ ¸å¿ƒçŸ›ç›¾ç‚¹",
          "æƒ…æ„Ÿå‘å±•": "è§’è‰²å…³ç³»çš„æ•´ä½“å‘å±•",
          "åç»­é“ºå«": "ä¸ºåç»­å‰§æƒ…è®¾ç½®çš„ä¼ç¬”"
        }}
      }}
    ]
  }}
}}
```

è¯·ç¡®ä¿ï¼š
1. å‡†ç¡®ç”Ÿæˆ **{story_count} ä¸ªå®Œæ•´çš„å¤§å‰§æƒ…**
2. **æ•…äº‹IDä½¿ç”¨ä¸´æ—¶ID**ï¼šç¬¬1ä¸ªå‰§æƒ…ä½¿ç”¨ TEMP_001ï¼Œç¬¬2ä¸ªä½¿ç”¨ TEMP_002ï¼Œä»¥æ­¤ç±»æ¨
3. **å°èŠ‚IDæ ¼å¼**ï¼šç¬¬1ä¸ªå‰§æƒ…çš„å°èŠ‚ä½¿ç”¨ STEMP_001_SCENE_001ã€STEMP_001_SCENE_002 ç­‰
4. æ¯ä¸ªå¤§å‰§æƒ…æ ¹æ®story_lengthè®¾ç½®ç”Ÿæˆç›¸åº”æ•°é‡çš„ç‹¬ç«‹å°èŠ‚ï¼š
   - short: 1-2ä¸ªç‹¬ç«‹å°èŠ‚
   - medium: 3-5ä¸ªç‹¬ç«‹å°èŠ‚  
   - long: 5-8ä¸ªç‹¬ç«‹å°èŠ‚
5. **å°èŠ‚å†…å®¹å¿…é¡»æ˜¯å®Œæ•´çš„æ•…äº‹æ®µè½**ï¼Œè‡ªç„¶èå…¥å››å¹•å¼ç»“æ„
6. **æ¯ä¸ªå°èŠ‚éƒ½å¿…é¡»åŒæ—¶å‡ºç°ä¸»è§’æ–¹çŸ¥è¡¡å’ŒæŒ‡å®šçš„å‚ä¸è§’è‰²**
7. **å°èŠ‚å®Œå…¨ç‹¬ç«‹**ï¼Œä¸ä¾èµ–å‰åå°èŠ‚çš„æ—¶é—´ç©ºé—´è”ç³»
8. **å¯¹è¯å’Œæƒ…æ„Ÿå˜åŒ–è‡ªç„¶èå…¥æ•…äº‹å†…å®¹**ï¼Œä¸å•ç‹¬åˆ†ç¦»
9. æ¯ä¸ªå°èŠ‚éƒ½æ˜¯ç‹¬ç«‹å®Œæ•´çš„ä¸€å¹•æ¼”ç»ï¼Œå¯ä»¥å•ç‹¬ä½¿ç”¨
10. å†…å®¹ç”ŸåŠ¨è¯¦ç»†ï¼ŒåŒ…å«åœºæ™¯æè¿°ã€è§’è‰²äº’åŠ¨ã€å†²çªè§£å†³
"""
        
        # æµå¼è°ƒç”¨LLM
        if llm:
            try:
                # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
                message = Message(role=MessageRole.USER, content=plot_prompt)
                messages = [message]
                
                logger.info(f"å‰§æƒ…ç”Ÿæˆ: å¼€å§‹æµå¼LLMè°ƒç”¨ï¼Œæç¤ºè¯é•¿åº¦: {len(plot_prompt)}")
                
                # ä½¿ç”¨thinkæ¨¡å¼æµå¼è°ƒç”¨
                chunk_count = 0
                think_content = ""
                final_content = ""
                
                async for chunk_data in llm.stream_generate(
                    messages, 
                    mode="think",
                    return_dict=True
                ):
                    chunk_count += 1
                    
                    think_part = chunk_data.get("think", "")
                    content_part = chunk_data.get("content", "")
                    
                    think_content += think_part
                    final_content += content_part
                    
                    # å®æ—¶æ›´æ–°UI
                    if workflow_chat:
                        try:
                            display_content = ""
                            if think_content.strip():
                                display_content += f"""
<div style="background: #f8f9fa; border-left: 4px solid #6c757d; padding: 10px; margin: 10px 0; border-radius: 4px;">
æ€è€ƒè¿‡ç¨‹ï¼š<br>
{think_content}
</div>"""
                            
                            if final_content.strip():
                                display_content += f"""
<div style="background: #e8f5e9; border-left: 4px solid #28a745; padding: 10px; margin: 10px 0; border-radius: 4px;">
ğŸ“– å‰§æƒ…å†…å®¹ï¼š<br>
{final_content}
</div>"""
                            
                            await workflow_chat.add_node_message(
                                "å‰§æƒ…ç”Ÿæˆ",
                                display_content,
                                "streaming"
                            )
                        except Exception as ui_error:
                            logger.warning(f"å‰§æƒ…ç”ŸæˆUIæ›´æ–°å¤±è´¥: {ui_error}")
                    
                    # æ¯ä¸ªchunkéƒ½yield
                    yield {
                        'plot_content': final_content,
                        'plot_think': think_content,
                        'chunk_progress': f"{chunk_count} chunks processed"
                    }
                
                logger.info(f"å‰§æƒ…ç”Ÿæˆ: æµå¼ç”Ÿæˆå®Œæˆï¼Œæ€»chunkæ•°: {chunk_count}ï¼Œå†…å®¹é•¿åº¦: {len(final_content)}")
                        
            except Exception as e:
                error_msg = f"å‰§æƒ…ç”ŸæˆLLMè°ƒç”¨å¤±è´¥: {type(e).__name__}: {str(e)}"
                logger.error(error_msg, exc_info=True)
                raise Exception(error_msg)
        else:
            error_msg = f"å‰§æƒ…ç”Ÿæˆ: LLMæœªåˆå§‹åŒ–"
            logger.error(error_msg)
            raise Exception(error_msg)
        
        # è§£æJSONæ ¼å¼çš„ç»“æœ
        try:
            from parsers.json_parser import JSONParser
            parser = JSONParser()
            
            json_content = self._extract_json_from_content(final_content)
            logger.info(f"æå–çš„JSONå†…å®¹é•¿åº¦: {len(json_content)} å­—ç¬¦")
            
            parsed_result = parser.parse(json_content)
            
            if parsed_result and 'story' in parsed_result:
                story_data = parsed_result['story']
                logger.info("æˆåŠŸè§£æå‰§æƒ…ç”ŸæˆJSONç»“æœï¼Œæ‰¾åˆ°storyå­—æ®µ")
            elif parsed_result and ('æ€»ä½“ä¿¡æ¯' in parsed_result or 'å‰§æƒ…åˆ—è¡¨' in parsed_result):
                # ç›´æ¥æ˜¯storyå†…å®¹æ ¼å¼
                story_data = parsed_result
                logger.info("æˆåŠŸè§£æå‰§æƒ…ç”ŸæˆJSONç»“æœï¼Œç›´æ¥æ˜¯storyå†…å®¹æ ¼å¼")
            else:
                logger.warning(f"å‰§æƒ…ç”ŸæˆJSONè§£æå¤±è´¥ï¼Œè§£æç»“æœé”®: {list(parsed_result.keys()) if parsed_result else 'None'}ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
                story_data = final_content
                
        except Exception as parse_error:
            logger.warning(f"å‰§æƒ…ç”ŸæˆJSONè§£æå¼‚å¸¸: {parse_error}ï¼Œfinal_contentå‰100å­—ç¬¦: {final_content[:100]}ï¼Œä½¿ç”¨åŸå§‹å†…å®¹")
            story_data = final_content
        
        output_data = input_data.copy()
        output_data['plot_content'] = story_data
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        logger.info(f"å‰§æƒ…ç”Ÿæˆå®Œæˆï¼Œplot_contentç±»å‹: {type(story_data)}, æ˜¯å¦ä¸ºdict: {isinstance(story_data, dict)}")
        if isinstance(story_data, dict):
            logger.info(f"plot_contentå­—å…¸é”®: {list(story_data.keys())}")
        
        print("âœ… å‰§æƒ…ç”Ÿæˆå®Œæˆ")
        yield output_data
    
    def _extract_json_from_content(self, content: str) -> str:
        """ä»ç”Ÿæˆå†…å®¹ä¸­æå–JSONéƒ¨åˆ†"""
        import re
        
        # æŸ¥æ‰¾```json...```ä»£ç å—
        json_pattern = r'```json\s*(.*?)\s*```'
        matches = re.findall(json_pattern, content, re.DOTALL | re.IGNORECASE)
        
        if matches:
            return matches[0].strip()
        
        # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•æŸ¥æ‰¾ä»¥{å¼€å¤´}ç»“å°¾çš„å†…å®¹
        json_pattern2 = r'\{.*\}'
        matches2 = re.findall(json_pattern2, content, re.DOTALL)
        
        if matches2:
            return matches2[0].strip()
        
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›åŸå†…å®¹
        return content.strip()


class DatabaseSaveNode(BaseNode):
    """æ•°æ®åº“ä¿å­˜èŠ‚ç‚¹ - å°†å‰§æƒ…æ•°æ®ä¿å­˜åˆ°SQLiteæ•°æ®åº“"""
    
    def __init__(self):
        super().__init__(name="database_save")
    
    async def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ•°æ®åº“ä¿å­˜"""
        print("ğŸ’¾ å¼€å§‹ä¿å­˜åˆ°æ•°æ®åº“...")
        
        workflow_chat = input_data.get('workflow_chat')
        plot_content = input_data.get('plot_content', '')
        config = input_data.get('config', {})
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        logger.info(f"æ•°æ®åº“ä¿å­˜èŠ‚ç‚¹æ¥æ”¶åˆ°plot_contentç±»å‹: {type(plot_content)}")
        if isinstance(plot_content, dict):
            logger.info(f"plot_contentå­—å…¸é”®: {list(plot_content.keys())}")
        elif isinstance(plot_content, str):
            logger.info(f"plot_contentå­—ç¬¦ä¸²é•¿åº¦: {len(plot_content)}ï¼Œå‰100å­—ç¬¦: {plot_content[:100]}")
        
        # æ›´æ–°UI - å¼€å§‹çŠ¶æ€
        if workflow_chat:
            await workflow_chat.add_node_message(
                "æ•°æ®åº“ä¿å­˜",
                "æ­£åœ¨è§£æå‰§æƒ…æ•°æ®å¹¶ä¿å­˜åˆ°SQLiteæ•°æ®åº“...",
                "progress"
            )
        
        try:
            from database import story_manager
            from datetime import datetime
            import json
            
            # è§£æå‰§æƒ…æ•°æ®
            story_data = None
            if isinstance(plot_content, dict):
                # å¦‚æœplot_contentæ˜¯dictï¼Œè¯´æ˜å‰é¢èŠ‚ç‚¹å·²ç»è§£ææˆåŠŸ
                # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œæ•´çš„storyæ•°æ®ç»“æ„è¿˜æ˜¯å·²ç»æå–çš„storyå†…å®¹
                if 'story' in plot_content:
                    # åŒ…å«storyå­—æ®µçš„å®Œæ•´JSON
                    story_data = plot_content['story']
                elif 'æ€»ä½“ä¿¡æ¯' in plot_content or 'å‰§æƒ…åˆ—è¡¨' in plot_content:
                    # å·²ç»æ˜¯storyå­—æ®µçš„å†…å®¹
                    story_data = plot_content
                else:
                    # å°è¯•ä½œä¸ºå®Œæ•´storyæ•°æ®ä½¿ç”¨
                    story_data = plot_content
                    
            elif isinstance(plot_content, str):
                # ä»å­—ç¬¦ä¸²ä¸­è§£æJSON
                try:
                    from parsers.json_parser import JSONParser
                    parser = JSONParser()
                    
                    json_content = self._extract_json_from_content(plot_content)
                    parsed_data = parser.parse(json_content)
                    
                    if parsed_data and 'story' in parsed_data:
                        story_data = parsed_data['story']
                    elif parsed_data and ('æ€»ä½“ä¿¡æ¯' in parsed_data or 'å‰§æƒ…åˆ—è¡¨' in parsed_data):
                        # ç›´æ¥æ˜¯storyå†…å®¹
                        story_data = parsed_data
                    else:
                        logger.error(f"JSONè§£æç»“æœæ ¼å¼ä¸æ­£ç¡®: {list(parsed_data.keys()) if parsed_data else 'None'}")
                        raise ValueError(f"æœªæ‰¾åˆ°æœ‰æ•ˆçš„å‰§æƒ…æ•°æ®ç»“æ„")
                        
                except Exception as parse_error:
                    logger.error(f"JSONè§£æå¤±è´¥: {parse_error}")
                    raise ValueError(f"æ— æ³•è§£æå‰§æƒ…æ•°æ®: {parse_error}")
            else:
                logger.error(f"æ— æ³•å¤„ç†çš„å‰§æƒ…æ•°æ®ç±»å‹: {type(plot_content)}")
                raise ValueError(f"æ— æ³•å¤„ç†çš„å‰§æƒ…æ•°æ®ç±»å‹: {type(plot_content)}")
            
            # éªŒè¯story_dataç»“æ„
            if not story_data:
                raise ValueError("è§£æåçš„å‰§æƒ…æ•°æ®ä¸ºç©º")
                
            # ç¡®ä¿story_dataæœ‰å¿…è¦çš„å­—æ®µ
            if not isinstance(story_data, dict):
                raise ValueError(f"å‰§æƒ…æ•°æ®ä¸æ˜¯å­—å…¸æ ¼å¼: {type(story_data)}")
                
            if 'å‰§æƒ…åˆ—è¡¨' not in story_data:
                raise ValueError("å‰§æƒ…æ•°æ®ç¼ºå°‘'å‰§æƒ…åˆ—è¡¨'å­—æ®µ")
                
            logger.info(f"æˆåŠŸè§£æå‰§æƒ…æ•°æ®: {len(story_data.get('å‰§æƒ…åˆ—è¡¨', []))} ä¸ªå‰§æƒ…")
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            success = story_manager.save_story_data(story_data, config)
            
            if not success:
                raise Exception("æ•°æ®åº“ä¿å­˜å¤±è´¥")
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = story_manager.get_story_statistics()
            
            # ç”ŸæˆCSVå¯¼å‡ºï¼ˆå¯é€‰ï¼‰
            csv_path = story_manager.export_story_data(format='csv')
            
            # ç”Ÿæˆç»“æœä¿¡æ¯
            story_count = len(story_data.get('å‰§æƒ…åˆ—è¡¨', []))
            total_scenes = sum(len(story.get('å‰§æƒ…å°èŠ‚', [])) for story in story_data.get('å‰§æƒ…åˆ—è¡¨', []))
            
            result = f"""âœ… æ•°æ®åº“ä¿å­˜æˆåŠŸï¼

# ä¿å­˜ä¿¡æ¯

- ä¿å­˜å‰§æƒ…æ•°ï¼š{story_count} ä¸ª
- ä¿å­˜å°èŠ‚æ•°ï¼š{total_scenes} ä¸ª
- ä¿å­˜æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

# æ•°æ®åº“ç»Ÿè®¡

- æ€»å‰§æƒ…æ•°ï¼š{stats.get('total_stories', 0)} ä¸ª
- æ€»å°èŠ‚æ•°ï¼š{stats.get('total_scenes', 0)} ä¸ª
- æ€»è§’è‰²æ•°ï¼š{stats.get('total_characters', 0)} ä¸ª
- æœ€æ–°åˆ›å»ºï¼š{stats.get('latest_creation', 'æœªçŸ¥')}

# å¯¼å‡ºæ–‡ä»¶

- CSVå¯¼å‡ºè·¯å¾„ï¼š{csv_path}
- å¯åœ¨å‰ç«¯æ•°æ®åº“ç®¡ç†ç•Œé¢æŸ¥çœ‹å’Œç¼–è¾‘æ•°æ®

# åç»­æ“ä½œ

- åœ¨å‰ç«¯"æ•°æ®åº“ç®¡ç†"é¡µé¢æŸ¥çœ‹å‰§æƒ…
- æŒ‰è§’è‰²ç­›é€‰æŸ¥çœ‹ç›¸å…³å‰§æƒ…
- ç›´æ¥ç¼–è¾‘æ•°æ®åº“è¡¨å†…å®¹
- å¯¼å‡ºæŒ‡å®šæ•°æ®ä¸ºCSVæ–‡ä»¶
"""
            
            # æ›´æ–°UI - å®ŒæˆçŠ¶æ€
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "æ•°æ®åº“ä¿å­˜",
                    result,
                    "completed"
                )
            
            output_data = input_data.copy()
            output_data['database_saved'] = True
            output_data['csv_export_path'] = csv_path
            output_data['saved_story_count'] = story_count
            output_data['saved_scene_count'] = total_scenes
            output_data['database_stats'] = stats
            
            print(f"âœ… æ•°æ®åº“ä¿å­˜å®Œæˆï¼Œå¯¼å‡ºCSV: {csv_path}")
            return output_data
            
        except Exception as e:
            error_msg = f"æ•°æ®åº“ä¿å­˜å¤±è´¥: {str(e)}"
            print(error_msg)
            logger.error(error_msg, exc_info=True)
            
            if workflow_chat:
                await workflow_chat.add_node_message(
                    "æ•°æ®åº“ä¿å­˜",
                    error_msg,
                    "error"
                )
            
            raise e
    
    def _extract_json_from_content(self, content: str) -> str:
        """ä»ç”Ÿæˆå†…å®¹ä¸­æå–JSONéƒ¨åˆ†"""
        import re
        
        # æŸ¥æ‰¾```json...```ä»£ç å—
        json_pattern = r'```json\s*(.*?)\s*```'
        matches = re.findall(json_pattern, content, re.DOTALL | re.IGNORECASE)
        
        if matches:
            return matches[0].strip()
        
        # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå°è¯•æŸ¥æ‰¾ä»¥{å¼€å¤´}ç»“å°¾çš„å†…å®¹
        json_pattern2 = r'\{.*\}'
        matches2 = re.findall(json_pattern2, content, re.DOTALL)
        
        if matches2:
            return matches2[0].strip()
        
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›åŸå†…å®¹
        return content.strip()