# -*- coding: utf-8 -*-
"""
LLMå®¢æˆ·ç«¯ - æ”¯æŒClaudeå’Œè±†åŒ…æ¨¡å‹çš„ç»Ÿä¸€æ¥å£
æ”¯æŒæ¨¡å‹ï¼š
- Claudeç³»åˆ— (Anthropic)
- è±†åŒ…ç³»åˆ— (å­—èŠ‚è·³åŠ¨)
- Kimiç³»åˆ— (æœˆä¹‹æš—é¢)
- DeepSeekç³»åˆ— (DeepSeek)
"""

import requests
import json
import time
import sys
from typing import Optional, Dict, Any, List
from enum import Enum

class LLMProvider(Enum):
    """LLMæä¾›å•†æšä¸¾"""
    CLAUDE = "claude"
    DOUBAO = "doubao"
    DEEPSEEK = "deepseek"

class LLMClient:
    """ç»Ÿä¸€çš„LLMå®¢æˆ·ç«¯ï¼Œæ”¯æŒå¤šä¸ªæ¨¡å‹æä¾›å•†"""
    
    # è±†åŒ…å¹³å°æ¨¡å‹æ˜ å°„
    DOUBAO_MODELS = {
        # è±†åŒ…æ¨¡å‹
        "doubao-1.5-pro-32k": "ep-20250312153153-npj4s",
        "doubao-1.5-lite-32k": "ep-20250312153312-hwtd2", 
        "doubao-1.5-pro-256k": "ep-20250312153332-jfhkj",
        "doubao-1.5-pro-character": "ep-20250312153655-ntg8z",
        "doubao-1.5-thinking-pro": "ep-20250417214536-hpndh",
        "doubao-1.6": "ep-20250612123019-mb9bb",
        "doubao-1.6-thinking": "ep-20250612123438-7fj94",
        "doubao-1.6-flash": "ep-20250612122042-t6g56",
        "doubao-embedding": "ep-20250312154514-xrm58",
        

        
        # DeepSeekæ¨¡å‹
        "deepseek-V3": "ep-20250221154410-vh78x",
        "deepseek-R1": "ep-20250221154107-c4qc7"
    }
    
    def __init__(self, 
                 provider: LLMProvider = LLMProvider.CLAUDE,
                 model: str = "claude-sonnet-4-20250514",
                 api_key: str = None,
                 base_url: str = None):
        """
        åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        
        Args:
            provider: LLMæä¾›å•† (CLAUDE, DOUBAO, KIMI, DEEPSEEK)
            model: æ¨¡å‹åç§°
            api_key: APIå¯†é’¥
            base_url: åŸºç¡€URL
        """
        self.provider = provider
        self.model = model
        self.api_key = api_key
        self.base_url = base_url
        
        # è®¾ç½®é»˜è®¤é…ç½®
        self._setup_default_config()
        
        print(f"ğŸ¤– LLMå®¢æˆ·ç«¯åˆå§‹åŒ–: {self.provider.value} - {self.model}")
        
    def _setup_default_config(self):
        """è®¾ç½®é»˜è®¤é…ç½®"""
        if self.provider == LLMProvider.CLAUDE:
            if not self.base_url:
                self.base_url = "https://club.claudecode.site"
            self.endpoint = f"{self.base_url}/v1/messages"
            
        elif self.provider in [LLMProvider.DOUBAO, LLMProvider.DEEPSEEK]:
            if not self.base_url:
                self.base_url = "https://ark.cn-beijing.volces.com/api/v3"
            self.endpoint = f"{self.base_url}/chat/completions"
            
            # å°†å‹å¥½åç§°è½¬æ¢ä¸ºendpoint ID
            if self.model in self.DOUBAO_MODELS:
                self.endpoint_id = self.DOUBAO_MODELS[self.model]
                print(f"ğŸ“‹ æ¨¡å‹æ˜ å°„: {self.model} -> {self.endpoint_id}")
            else:
                self.endpoint_id = self.model  # å¦‚æœç›´æ¥æä¾›endpoint ID
    
    def call(self, system_prompt_or_full_prompt: str, 
             user_message: Optional[str] = None,
             agent_name: str = "Assistant",
             max_tokens: int = 2000,
             temperature: float = 0.7,
             stream: bool = True) -> str:
        """
        è°ƒç”¨LLM APIçš„ç»Ÿä¸€æ¥å£ - æ”¯æŒåˆ†ç¦»çš„ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æ¶ˆæ¯
        
        Args:
            system_prompt_or_full_prompt: ç³»ç»Ÿæç¤ºè¯ï¼Œå¦‚æœuser_messageä¸ºNoneï¼Œåˆ™ä½œä¸ºå®Œæ•´æç¤º
            user_message: ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚æœæä¾›åˆ™ä¸system_promptåˆ†ç¦»
            agent_name: ä»£ç†åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            max_tokens: æœ€å¤§tokenæ•°
            temperature: æ¸©åº¦å‚æ•°
            stream: æ˜¯å¦æµå¼è¾“å‡º
            
        Returns:
            str: LLMå“åº”å†…å®¹
        """
        if not self.api_key:
            error_msg = f"âŒ [{agent_name}] æœªé…ç½®{self.provider.value} APIå¯†é’¥"
            print(error_msg, flush=True)
            return error_msg
        
        print(f"ğŸ¤– [{agent_name}] è°ƒç”¨{self.provider.value}æ¨¡å‹: {self.model}", flush=True)
        
        try:
            if self.provider == LLMProvider.CLAUDE:
                return self._call_claude_api(system_prompt_or_full_prompt, user_message, agent_name, max_tokens, stream)
            else:
                return self._call_doubao_api(system_prompt_or_full_prompt, user_message, agent_name, max_tokens, temperature, stream)
                
        except Exception as e:
            error_msg = f"âŒ [{agent_name}] {self.provider.value}è°ƒç”¨å¤±è´¥: {e}"
            print(error_msg, flush=True)
            return error_msg
    
    def _call_claude_api(self, system_prompt_or_full_prompt: str, user_message: Optional[str], 
                         agent_name: str, max_tokens: int, stream: bool) -> str:
        """è°ƒç”¨Claude API - æ”¯æŒåˆ†ç¦»çš„ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æ¶ˆæ¯"""
        if user_message is not None:
            # åˆ†ç¦»æ¨¡å¼ï¼šç³»ç»Ÿæç¤º + ç”¨æˆ·æ¶ˆæ¯
            payload = {
                "model": self.model,
                "system": system_prompt_or_full_prompt,
                "messages": [{"role": "user", "content": user_message}],
                "max_tokens": max_tokens,
                "stream": stream
            }
        else:
            # å…¼å®¹æ¨¡å¼ï¼šå•ä¸ªå®Œæ•´æç¤º
            payload = {
                "model": self.model,
                "messages": [{"role": "user", "content": system_prompt_or_full_prompt}],
                "max_tokens": max_tokens,
                "stream": stream
            }
        
        headers = {
            "x-api-key": self.api_key,
            "Content-Type": "application/json"
        }
        
        return self._make_request(payload, headers, agent_name, stream)
    
    def _call_doubao_api(self, system_prompt_or_full_prompt: str, user_message: Optional[str], 
                         agent_name: str, max_tokens: int, temperature: float, stream: bool) -> str:
        """è°ƒç”¨è±†åŒ…/Kimi/DeepSeek API - æ”¯æŒåˆ†ç¦»çš„ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æ¶ˆæ¯"""
        if user_message is not None:
            # åˆ†ç¦»æ¨¡å¼ï¼šç³»ç»Ÿæç¤º + ç”¨æˆ·æ¶ˆæ¯  
            messages = [
                {"role": "system", "content": system_prompt_or_full_prompt},
                {"role": "user", "content": user_message}
            ]
        else:
            # å…¼å®¹æ¨¡å¼ï¼šå•ä¸ªå®Œæ•´æç¤º
            messages = [{"role": "user", "content": system_prompt_or_full_prompt}]
            
        payload = {
            "model": self.endpoint_id,  # ä½¿ç”¨endpoint ID
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "stream": stream
        }
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        return self._make_request(payload, headers, agent_name, stream)
    
    def _make_request(self, payload: dict, headers: dict, agent_name: str, stream: bool) -> str:
        """å‘é€HTTPè¯·æ±‚"""
        try:
            response = requests.post(self.endpoint, json=payload, headers=headers, timeout=60, stream=stream)
            
            if response.status_code != 200:
                error_msg = f"âŒ [{agent_name}] APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}"
                print(error_msg)
                

                
                return error_msg
            
            if stream:
                return self._handle_stream_response(response, agent_name)
            else:
                return self._handle_normal_response(response, agent_name)
                
        except requests.exceptions.Timeout:
            error_msg = f"âŒ [{agent_name}] è¯·æ±‚è¶…æ—¶"
            print(error_msg)
            return error_msg
        except requests.exceptions.RequestException as e:
            error_msg = f"âŒ [{agent_name}] ç½‘ç»œè¯·æ±‚é”™è¯¯: {e}"
            print(error_msg)
            return error_msg
    
    def _handle_stream_response(self, response, agent_name: str) -> str:
        """å¤„ç†æµå¼å“åº”"""
        full_response = ""
        buffer = ""
        
        try:
            for chunk in response:
                if chunk:
                    buffer += chunk.decode('utf-8', errors='ignore')
                    
                    # å¤„ç†å®Œæ•´çš„è¡Œ
                    while '\n' in buffer:
                        line, buffer = buffer.split('\n', 1)
                        line = line.strip()
                        
                        if line.startswith('data: '):
                            data_text = line[6:]
                            if data_text.strip() == '[DONE]':
                                break
                            
                            try:
                                data = json.loads(data_text)
                                
                                # Claudeæ ¼å¼
                                if self.provider == LLMProvider.CLAUDE:
                                    if data.get('type') == 'content_block_delta':
                                        if 'delta' in data and data['delta'].get('type') == 'text_delta':
                                            chunk_text = data['delta']['text']
                                            print(chunk_text, end='', flush=True)
                                            sys.stdout.flush()
                                            full_response += chunk_text
                                
                                # è±†åŒ…/Kimi/DeepSeekæ ¼å¼
                                else:
                                    if 'choices' in data and len(data['choices']) > 0:
                                        choice = data['choices'][0]
                                        if 'delta' in choice and 'content' in choice['delta']:
                                            chunk_text = choice['delta']['content']
                                            if chunk_text:
                                                print(chunk_text, end='', flush=True)
                                                sys.stdout.flush()
                                                full_response += chunk_text
                                                
                            except json.JSONDecodeError:
                                continue
                            except Exception as e:
                                print(f"âš ï¸ [{agent_name}] å¤„ç†æ•°æ®é”™è¯¯: {e}")
                                continue
            
            print()  # æ¢è¡Œ
            
            if not full_response.strip():
                error_msg = f"âŒ [{agent_name}] æœªæ”¶åˆ°æœ‰æ•ˆå“åº”å†…å®¹"
                print(error_msg)
                return error_msg
            
            return full_response.strip()
            
        except Exception as e:
            error_msg = f"âŒ [{agent_name}] æµå¼å“åº”å¤„ç†é”™è¯¯: {e}"
            print(error_msg)
            return error_msg
    
    def _handle_normal_response(self, response, agent_name: str) -> str:
        """å¤„ç†æ™®é€šå“åº”"""
        try:
            data = response.json()
            
            # Claudeæ ¼å¼
            if self.provider == LLMProvider.CLAUDE:
                if 'content' in data and len(data['content']) > 0:
                    return data['content'][0]['text']
            
            # è±†åŒ…/Kimi/DeepSeekæ ¼å¼
            else:
                if 'choices' in data and len(data['choices']) > 0:
                    return data['choices'][0]['message']['content']
            
            error_msg = f"âŒ [{agent_name}] å“åº”æ ¼å¼å¼‚å¸¸"
            print(error_msg)
            return error_msg
            
        except Exception as e:
            error_msg = f"âŒ [{agent_name}] å“åº”è§£æé”™è¯¯: {e}"
            print(error_msg)
            return error_msg

# ä¾¿æ·çš„å·¥å‚å‡½æ•°
def create_claude_client(api_key: str, model: str = "claude-sonnet-4-20250514", base_url: str = None) -> LLMClient:
    """åˆ›å»ºClaudeå®¢æˆ·ç«¯"""
    return LLMClient(
        provider=LLMProvider.CLAUDE,
        model=model,
        api_key=api_key,
        base_url=base_url
    )

def create_doubao_client(api_key: str, model: str = "doubao-1.6", base_url: str = None) -> LLMClient:
    """åˆ›å»ºè±†åŒ…å®¢æˆ·ç«¯"""
    return LLMClient(
        provider=LLMProvider.DOUBAO,
        model=model,
        api_key=api_key,
        base_url=base_url
    )



def create_deepseek_client(api_key: str, model: str = "deepseek-V3", base_url: str = None) -> LLMClient:
    """åˆ›å»ºDeepSeekå®¢æˆ·ç«¯"""
    return LLMClient(
        provider=LLMProvider.DEEPSEEK,
        model=model,
        api_key=api_key,
        base_url=base_url
    )

# æµ‹è¯•å‡½æ•°
def test_llm_client():
    """æµ‹è¯•LLMå®¢æˆ·ç«¯"""
    print("ğŸ§ª LLMå®¢æˆ·ç«¯æµ‹è¯•")
    
    # æµ‹è¯•è±†åŒ…æ¨¡å‹
    doubao_client = create_doubao_client(
        api_key="b633a622-b5d0-4f16-a8a9-616239cf15d1",
        model="doubao-1.6"
    )
    
    response = doubao_client.call("ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±", "æµ‹è¯•ä»£ç†", max_tokens=100, stream=False)
    print(f"è±†åŒ…å“åº”: {response}")
    
    # æµ‹è¯•DeepSeekæ¨¡å‹
    deepseek_client = create_deepseek_client(
        api_key="b633a622-b5d0-4f16-a8a9-616239cf15d1",
        model="deepseek-V3"
    )
    
    response = deepseek_client.call("ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±", "æµ‹è¯•ä»£ç†", max_tokens=100, stream=False)
    print(f"DeepSeekå“åº”: {response}")

if __name__ == "__main__":
    test_llm_client()
